{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T05:54:30.915851Z",
     "start_time": "2018-01-30T05:54:23.659673Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "\n",
    "#from data import v2, v1, AnnotationTransform, VOCDetection, detection_collate, VOCroot, VOC_CLASSES\n",
    "from data import v2, v1, detection_collate\n",
    "from data import MSCOCODetection, COCOAnnotationTransform\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "COMMON_CLASSES = ('person', 'bicycle', 'car',\n",
    "                  'bus', 'train', 'boat',\n",
    "                   'bird', 'cat', 'dog',\n",
    "                   'horse', 'sheep', 'cow',\n",
    "                   'bottle', 'chair', 'airplane',\n",
    "                 'dining table', 'potted plant', 'tv',\n",
    "                 'motorcycle', 'couch')\n",
    "\n",
    "#hyperparameters\n",
    "\n",
    "version = \"v2\"\n",
    "basenet = \"vgg16_reducedfc.pth\"\n",
    "jaccard_threshold=0.5\n",
    "lr=1e-5\n",
    "cwd = os.getcwd()\n",
    "save_folder=cwd + \"/MSCOCO14weights/\"\n",
    "\n",
    "voc_root= \"/new_data/gpu/utkrsh/coco/\" # location of the image root directory\n",
    "\n",
    "annFile = \"/new_data/gpu/utkrsh/coco/annotations/instances_train2014.json\"\n",
    "train_img = \"/new_data/gpu/utkrsh/coco/images/train2014/\"\n",
    "\n",
    "cuda=True\n",
    "resume = \"./MSCOCO14weights/ssd300_COCO_8000.pth\" # saved trained weights\n",
    "start_iter=8001\n",
    "\n",
    "if cuda and torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "#train_sets = [('2007', 'trainval'), ('2012', 'trainval')]\n",
    "# train_sets = 'train'\n",
    "ssd_dim = 300  # only support 300 now\n",
    "means = (104, 117, 123)  # imagenet mean values\n",
    "num_classes = len(COMMON_CLASSES) + 1\n",
    "batch_size = 32\n",
    "accum_batch_size = 32\n",
    "iter_size = accum_batch_size / batch_size\n",
    "max_iter = 120000\n",
    "weight_decay = 0.0005\n",
    "stepvalues = (10000, 20000, 40000, 80000, 100000, 120000)\n",
    "gamma = 0.1\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T15:40:17.065558Z",
     "start_time": "2018-01-28T15:40:15.239705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training, loading weights from ./MSCOCO14weights/ssd300_COCO_8000.pth...\n",
      "Loading weights into state dict...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "ssd_net = build_ssd('train', 300, num_classes)\n",
    "net = ssd_net\n",
    "\n",
    "net = torch.nn.DataParallel(ssd_net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if resume:\n",
    "    print(\"Resuming training, loading weights from {}...\".format(resume))\n",
    "    ssd_net.load_weights(resume)\n",
    "else:\n",
    "    vgg_weights = torch.load(save_folder + basenet)\n",
    "    print('Loading base network...')\n",
    "    ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "if cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "if not resume:\n",
    "    print('Initializing weights...')\n",
    "    # initialize newly added layers' weights with xavier method\n",
    "    ssd_net.extras.apply(weights_init)\n",
    "    ssd_net.loc.apply(weights_init)\n",
    "    ssd_net.conf.apply(weights_init)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = MultiBoxLoss(num_classes, 0.5, True, 0, True, 3, 0.5, False, cuda)\n",
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    global lr\n",
    "    lr = lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-28T15:40:17.200183Z",
     "start_time": "2018-01-28T15:40:17.067082Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_detection_collate(batch):\n",
    "    \"\"\"Custom collate fn for dealing with batches of images that have a different\n",
    "    number of associated object annotations (bounding boxes).\n",
    "\n",
    "    Arguments:\n",
    "        batch: (tuple) A tuple of tensor images and lists of annotations\n",
    "\n",
    "    Return:\n",
    "        A tuple containing:\n",
    "            1) (tensor) batch of images stacked on their 0 dim\n",
    "            2) (list of tensors) annotations for a given image are stacked on 0 dim\n",
    "    \"\"\"\n",
    "    targets_1 = []\n",
    "    imgs = []\n",
    "    for sample in batch:\n",
    "        # each sample is the result of one query on the dataset object\n",
    "        imgs.append(sample[0])\n",
    "        targets_1.append(torch.FloatTensor(sample[1]))\n",
    "    return torch.stack(imgs, 0), targets_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-28T15:40:03.323Z"
    },
    "code_folding": [
     39
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    # loss counters\n",
    "    loc_loss = 0  # epoch\n",
    "    conf_loss = 0\n",
    "    epoch = 0\n",
    "    loss_prev = None\n",
    "    save_weights = True\n",
    "    print_interval = 10\n",
    "    curr_skip = 0\n",
    "    max_skip = 2\n",
    "    \n",
    "    print('Loading Dataset...')\n",
    "    \n",
    "    dataset = MSCOCODetection(image_root=train_img, ann_root=annFile, \n",
    "                              transform=SSDAugmentation(ssd_dim, means), \n",
    "                              target_transform=COCOAnnotationTransform())\n",
    "    #dataset = MSCOCODetection(image_root=train_img, ann_root=annFile)\n",
    "    print(\"Dataset Loaded!\")\n",
    "    \n",
    "    epoch_size = len(dataset) // batch_size\n",
    "    print(\"Training SSD on\", dataset.name)\n",
    "    step_index = 0\n",
    "    batch_iterator = None\n",
    "    data_loader = data.DataLoader(dataset, batch_size, num_workers=0,\n",
    "                             shuffle=True, collate_fn=my_detection_collate,\n",
    "                             pin_memory=cuda)\n",
    "    \n",
    "    for iteration in range(start_iter, max_iter):\n",
    "        if(not batch_iterator) or (iteration % epoch_size == 0):\n",
    "            # create batch_iterator\n",
    "            batch_iterator = iter(data_loader)\n",
    "        if iteration in stepvalues:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, gamma, step_index)\n",
    "            # reset epoch loss counters\n",
    "            epoch += 1\n",
    "        \n",
    "        images, targets = next(batch_iterator)\n",
    "        if cuda:\n",
    "            images = Variable(images.cuda())\n",
    "            targets = [Variable(anno.cuda(), volatile=True) for anno in targets]\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            targets = [Variable(anno, volatile=True) for anno in targets]\n",
    "        \n",
    "        # forward pass\n",
    "        t0 = time.time()\n",
    "        out = net(images)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss_l, loss_c = criterion(out, targets)\n",
    "        loss = loss_l + loss_c\n",
    "        if loss_prev is None:\n",
    "            loss_prev = loss.data\n",
    "        else:\n",
    "            # https://discuss.pytorch.org/t/how-to-use-condition-flow/644/5\n",
    "            if  (torch.abs(loss_prev - loss.data) < 100000).all():\n",
    "                loss_prev = loss.data\n",
    "            else:\n",
    "                # loss value more than enough deviation\n",
    "                # skip over the current batch\n",
    "                if curr_skip < max_skip:\n",
    "                    curr_skip = curr_skip + 1\n",
    "                    continue\n",
    "                else:\n",
    "                    # save the current model input\n",
    "                    dump = {}\n",
    "                    dump['out'] = out\n",
    "                    dump['targets'] = targets\n",
    "                    dump['loss_l'] = loss_l\n",
    "                    dump['loss_c'] = loss_c\n",
    "                    dump['loss_prev'] = loss_prev\n",
    "                    dump['loss'] = loss\n",
    "                    with open(\"./MSCOCO14weights/fail_dump.pkl\",\"wb\") as f:\n",
    "                        torch.save(dump,f)\n",
    "                    sys.exit(\"Loss with NaN values. Check log and dump file\")\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        if iteration % print_interval == 0:\n",
    "            print(\"Timer: %.4f sec. \" % (t1 - t0))\n",
    "            print(\"iter: \"+ repr(iteration) + \"|| loss_loc: %.4f || loss_conf: %.4f || loss: %.4f || \" \n",
    "                  % (loss_l.data[0], loss_c.data[0], loss.data[0]), end=' ')\n",
    "            try:\n",
    "                with open(\"./MSCOCO14weights/run.txt\",\"a+\") as f:\n",
    "                    f.write(\"iter: \"+ repr(iteration) + \"|| loss_loc: %.4f || loss_conf: %.4f || loss: %.4f \\n \" \n",
    "                            % (loss_l.data[0], loss_c.data[0], loss.data[0]))\n",
    "            except:\n",
    "                print(\"Cannot open log file\")\n",
    "        if iteration % 2000 == 0 and save_weights:\n",
    "            try:\n",
    "                print(\" Saving state, iter: \", iteration)\n",
    "                torch.save(ssd_net.state_dict(), \"./MSCOCO14weights/ssd300_COCO_\" +\n",
    "                          repr(iteration) + \".pth\")\n",
    "            except IOError:\n",
    "                with open(\"./MSCOCO14weights/run.txt\",\"a+\") as f:\n",
    "                    f.write(\"Some file related error in saving the model state\\n\")\n",
    "                print(\"Some file related eror in saving\")\n",
    "            except:\n",
    "                with open(\"./MSCOCO14weights/run.txt\",\"a+\") as f:\n",
    "                    f.write(\"Some other error while saving the model stats\\n\")\n",
    "                print(\"Some other error while saving\")\n",
    "    torch.save(ssd_net.state_dict(), save_folder+\"final_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-01-28T15:40:03.326Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "loading annotations into memory...\n",
      "Done (t=8.54s)\n",
      "creating index...\n",
      "index created!\n",
      "Dataset Loaded!\n",
      "Training SSD on COCO2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py:450: UserWarning: mask is not broadcastable to self, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return tensor.masked_fill_(mask, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.1594 sec. \n",
      "iter: 8010|| loss_loc: 2.6002 || loss_conf: 4.4105 || loss: 7.0107 ||  Timer: 0.1578 sec. \n",
      "iter: 8020|| loss_loc: 2.2732 || loss_conf: 4.4052 || loss: 6.6785 ||  "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "d_iter = iter(data_loader)\n",
    "d_img, d_targets = next(d_iter)\n",
    "if cuda:\n",
    "    d_img = Variable(d_img.cuda())\n",
    "else:\n",
    "    d_img = Variable(d_img)\n",
    "d_out = net(d_img)\n",
    "if cuda:\n",
    "    d_targets = [Variable(anno.cuda(), volatile=True) for anno in d_targets]\n",
    "else:\n",
    "    d_targets = [Variable(anno, volatile=True) for anno in d_targets]\n",
    "\n",
    "print(d_targets)\n",
    "\n",
    "import traceback\n",
    "\n",
    "try:\n",
    "    d_loss1, d_loss2 = criterion(d_out, d_targets)\n",
    "except:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
