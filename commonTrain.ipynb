{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T18:25:42.736362Z",
     "start_time": "2018-02-03T18:25:41.069398Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "#CHANGE\n",
    "from data import v2, v1, AnnotationTransform, VOCDetection, detection_collate, VOC_CLASSES\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import numpy as np\n",
    "import time\n",
    "from commonData import commonDataset\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "#CHANGE\n",
    "cocoimgPath = \"/new_data/gpu/utkrsh/coco/images/train2014/\"\n",
    "annFilePath = \"/new_data/gpu/utkrsh/coco/annotations/instances_train2014.json\"\n",
    "RESUME = \"./weights/ssd300_0712_COCO14_2000_run2_BCELoss.pth\" # change to saved model file path\n",
    "START_ITER = 2001\n",
    "CUDA = True\n",
    "VOCroot = \"/users/gpu/utkrsh/data/VOCdevkit/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T18:25:42.754725Z",
     "start_time": "2018-02-03T18:25:42.739557Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version ='v2'\n",
    "basenet ='vgg16_reducedfc.pth'\n",
    "jaccard_threshold = 0.5\n",
    "batch_size = 16\n",
    "resume = RESUME\n",
    "num_workers = 4\n",
    "iterations = 120000\n",
    "start_iter = START_ITER\n",
    "cuda = CUDA\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "gamma = 0.1\n",
    "log_iters = False\n",
    "visdom = False\n",
    "send_images_to_visdom = False\n",
    "save_folder = 'weights/'\n",
    "cocoimg = cocoimgPath\n",
    "annFile = annFilePath\n",
    "voc_root = VOCroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T18:25:50.342028Z",
     "start_time": "2018-02-03T18:25:42.756188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training, loading ./weights/ssd300_0712_COCO14_2000_run2_BCELoss.pth...\n",
      "Loading weights into state dict...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "if cuda and torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "cfg = (v1, v2)[version == 'v2']\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "train_sets = [('2007', 'trainval')]\n",
    "# train_sets = 'train'\n",
    "ssd_dim = 300  # only support 300 now\n",
    "means = (104, 117, 123)  # only support voc now\n",
    "num_classes = len(VOC_CLASSES) + 1\n",
    "batch_size = batch_size\n",
    "accum_batch_size = 32\n",
    "iter_size = accum_batch_size / batch_size\n",
    "max_iter = 120000\n",
    "weight_decay = 0.0005\n",
    "stepvalues = (80000, 100000, 120000)\n",
    "gamma = 0.1\n",
    "momentum = 0.9\n",
    "\n",
    "if visdom:\n",
    "    import visdom\n",
    "    viz = visdom.Visdom()\n",
    "\n",
    "ssd_net = build_ssd('train', 300, num_classes)\n",
    "net = ssd_net\n",
    "\n",
    "if False:\n",
    "    net = torch.nn.DataParallel(ssd_net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if resume:\n",
    "    print('Resuming training, loading {}...'.format(resume))\n",
    "    ssd_net.load_weights(resume)\n",
    "else:\n",
    "    vgg_weights = torch.load(save_folder + basenet)\n",
    "    print('Loading base network...')\n",
    "    ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "if cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "if not resume:\n",
    "    print('Initializing weights...')\n",
    "    # initialize newly added layers' weights with xavier method\n",
    "    ssd_net.extras.apply(weights_init)\n",
    "    ssd_net.loc.apply(weights_init)\n",
    "    ssd_net.conf.apply(weights_init)\n",
    "#CHANGE\n",
    "    ssd_net.dmn.apply(weights_init)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = MultiBoxLoss(num_classes, 0.5, True, 0, True, 3, 0.5, False, cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T11:31:50.730741Z",
     "start_time": "2018-02-03T11:31:40.410291Z"
    }
   },
   "source": [
    "dataset = commonDataset(voc_root, train_sets, ssd_dim, means,\n",
    "                cocoimg, annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T11:31:53.182217Z",
     "start_time": "2018-02-03T11:31:52.979601Z"
    },
    "collapsed": true
   },
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size, num_workers=num_workers,\n",
    "                              shuffle=True, collate_fn=detection_collate, pin_memory=True)\n",
    "batch_iter = iter(data_loader)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img, targets = next(batch_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T18:25:50.356498Z",
     "start_time": "2018-02-03T18:25:50.346113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD (\n",
       "  (vgg): ModuleList (\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU (inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU (inplace)\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU (inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU (inplace)\n",
       "    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU (inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU (inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU (inplace)\n",
       "    (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU (inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU (inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU (inplace)\n",
       "    (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU (inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU (inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU (inplace)\n",
       "    (30): MaxPool2d (size=(3, 3), stride=(1, 1), padding=(1, 1), dilation=(1, 1))\n",
       "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "    (32): ReLU (inplace)\n",
       "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (34): ReLU (inplace)\n",
       "  )\n",
       "  (L2Norm): L2Norm (\n",
       "  )\n",
       "  (extras): ModuleList (\n",
       "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (dmn): ModuleList (\n",
       "    (0): Linear (739328 -> 128)\n",
       "    (1): Sigmoid ()\n",
       "    (2): Linear (128 -> 64)\n",
       "    (3): Sigmoid ()\n",
       "    (4): Linear (64 -> 64)\n",
       "    (5): Sigmoid ()\n",
       "    (6): Linear (64 -> 1)\n",
       "    (7): Sigmoid ()\n",
       "  )\n",
       "  (loc): ModuleList (\n",
       "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf): ModuleList (\n",
       "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T18:25:50.504129Z",
     "start_time": "2018-02-03T18:25:50.362188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T19:07:16.990971Z",
     "start_time": "2018-02-03T18:25:50.507360Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "loading annotations into memory...\n",
      "Done (t=9.30s)\n",
      "creating index...\n",
      "index created!\n",
      "Training SSD on VOC07_and_COCO14_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py:450: UserWarning: mask is not broadcastable to self, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return tensor.masked_fill_(mask, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.2143 sec.\n",
      "iter : 2010 || loc: 2.9447 || conf: 5.8861 || dom: 0.0017 || loss: 8.8325 ||\n",
      "\n",
      "Timer: 0.1963 sec.\n",
      "iter : 2020 || loc: 2.6709 || conf: 7.0412 || dom: 0.0018 || loss: 9.7139 ||\n",
      "\n",
      "Timer: 0.2027 sec.\n",
      "iter : 2030 || loc: 2.9040 || conf: 8.1712 || dom: 0.0012 || loss: 11.0764 ||\n",
      "\n",
      "Timer: 0.2004 sec.\n",
      "iter : 2040 || loc: 3.0880 || conf: 6.4760 || dom: 0.0012 || loss: 9.5652 ||\n",
      "\n",
      "Timer: 0.1958 sec.\n",
      "iter : 2050 || loc: 3.0226 || conf: 6.0363 || dom: 0.0014 || loss: 9.0603 ||\n",
      "\n",
      "Timer: 0.2007 sec.\n",
      "iter : 2060 || loc: 2.2830 || conf: 6.0580 || dom: 0.0011 || loss: 8.3421 ||\n",
      "\n",
      "Timer: 0.1909 sec.\n",
      "iter : 2070 || loc: 3.1656 || conf: 6.4843 || dom: 0.0016 || loss: 9.6516 ||\n",
      "\n",
      "Timer: 0.2146 sec.\n",
      "iter : 2080 || loc: 2.7288 || conf: 5.2525 || dom: 0.0018 || loss: 7.9830 ||\n",
      "\n",
      "Timer: 0.1998 sec.\n",
      "iter : 2090 || loc: 2.4715 || conf: 6.1795 || dom: 0.0019 || loss: 8.6529 ||\n",
      "\n",
      "Timer: 0.2053 sec.\n",
      "iter : 2100 || loc: 3.0989 || conf: 7.3395 || dom: 0.0016 || loss: 10.4400 ||\n",
      "\n",
      "Timer: 0.2013 sec.\n",
      "iter : 2110 || loc: 2.8040 || conf: 7.6959 || dom: 0.0016 || loss: 10.5015 ||\n",
      "\n",
      "Timer: 0.1978 sec.\n",
      "iter : 2120 || loc: 2.1734 || conf: 4.3138 || dom: 0.0013 || loss: 6.4885 ||\n",
      "\n",
      "Timer: 0.2003 sec.\n",
      "iter : 2130 || loc: 2.6026 || conf: 6.7473 || dom: 0.0016 || loss: 9.3516 ||\n",
      "\n",
      "Timer: 0.1929 sec.\n",
      "iter : 2140 || loc: 2.5542 || conf: 5.9428 || dom: 0.0012 || loss: 8.4982 ||\n",
      "\n",
      "Timer: 0.2050 sec.\n",
      "iter : 2150 || loc: 2.5045 || conf: 6.9226 || dom: 0.0020 || loss: 9.4290 ||\n",
      "\n",
      "Timer: 0.1975 sec.\n",
      "iter : 2160 || loc: 2.1482 || conf: 5.2333 || dom: 0.0019 || loss: 7.3835 ||\n",
      "\n",
      "Timer: 0.2005 sec.\n",
      "iter : 2170 || loc: 2.3542 || conf: 5.1638 || dom: 0.0014 || loss: 7.5193 ||\n",
      "\n",
      "Timer: 0.1920 sec.\n",
      "iter : 2180 || loc: 2.0471 || conf: 5.9375 || dom: 0.0027 || loss: 7.9873 ||\n",
      "\n",
      "Timer: 0.1978 sec.\n",
      "iter : 2190 || loc: 2.6182 || conf: 5.4757 || dom: 0.0019 || loss: 8.0957 ||\n",
      "\n",
      "Timer: 0.2040 sec.\n",
      "iter : 2200 || loc: 2.8262 || conf: 6.3262 || dom: 0.0022 || loss: 9.1547 ||\n",
      "\n",
      "Timer: 0.1954 sec.\n",
      "iter : 2210 || loc: 2.5803 || conf: 6.2948 || dom: 0.0017 || loss: 8.8768 ||\n",
      "\n",
      "Timer: 0.2111 sec.\n",
      "iter : 2220 || loc: 2.8192 || conf: 5.9406 || dom: 0.0017 || loss: 8.7615 ||\n",
      "\n",
      "Timer: 0.2049 sec.\n",
      "iter : 2230 || loc: 2.9966 || conf: 9.5841 || dom: 0.0019 || loss: 12.5826 ||\n",
      "\n",
      "Timer: 0.2096 sec.\n",
      "iter : 2240 || loc: 3.0215 || conf: 5.0005 || dom: 0.0015 || loss: 8.0235 ||\n",
      "\n",
      "Timer: 0.2048 sec.\n",
      "iter : 2250 || loc: 3.4221 || conf: 5.4832 || dom: 0.0015 || loss: 8.9069 ||\n",
      "\n",
      "Timer: 0.2005 sec.\n",
      "iter : 2260 || loc: 2.1955 || conf: 6.6639 || dom: 0.0015 || loss: 8.8609 ||\n",
      "\n",
      "Timer: 0.2061 sec.\n",
      "iter : 2270 || loc: 2.6065 || conf: 7.1098 || dom: 0.0015 || loss: 9.7178 ||\n",
      "\n",
      "Timer: 0.2075 sec.\n",
      "iter : 2280 || loc: 2.5794 || conf: 5.7767 || dom: 0.0015 || loss: 8.3576 ||\n",
      "\n",
      "Timer: 0.2068 sec.\n",
      "iter : 2290 || loc: 3.3471 || conf: 6.1722 || dom: 0.0017 || loss: 9.5209 ||\n",
      "\n",
      "Timer: 0.2080 sec.\n",
      "iter : 2300 || loc: 2.3535 || conf: 5.9833 || dom: 0.0014 || loss: 8.3383 ||\n",
      "\n",
      "Timer: 0.2084 sec.\n",
      "iter : 2310 || loc: 2.5445 || conf: 5.3737 || dom: 0.0016 || loss: 7.9198 ||\n",
      "\n",
      "Timer: 0.2124 sec.\n",
      "iter : 2320 || loc: 2.6947 || conf: 6.6026 || dom: 0.0009 || loss: 9.2982 ||\n",
      "\n",
      "Timer: 0.2120 sec.\n",
      "iter : 2330 || loc: 3.2268 || conf: 5.9719 || dom: 0.0015 || loss: 9.2003 ||\n",
      "\n",
      "Timer: 0.2015 sec.\n",
      "iter : 2340 || loc: 2.2712 || conf: 5.4434 || dom: 0.0017 || loss: 7.7163 ||\n",
      "\n",
      "Timer: 0.2068 sec.\n",
      "iter : 2350 || loc: 3.1450 || conf: 6.0308 || dom: 0.0014 || loss: 9.1773 ||\n",
      "\n",
      "Timer: 0.2084 sec.\n",
      "iter : 2360 || loc: 2.5293 || conf: 5.9042 || dom: 0.0014 || loss: 8.4349 ||\n",
      "\n",
      "Timer: 0.2030 sec.\n",
      "iter : 2370 || loc: 2.5364 || conf: 4.8051 || dom: 0.0014 || loss: 7.3429 ||\n",
      "\n",
      "Timer: 0.2046 sec.\n",
      "iter : 2380 || loc: 2.7958 || conf: 5.9292 || dom: 0.0010 || loss: 8.7259 ||\n",
      "\n",
      "Timer: 0.2018 sec.\n",
      "iter : 2390 || loc: 2.5403 || conf: 5.6148 || dom: 0.0015 || loss: 8.1566 ||\n",
      "\n",
      "Timer: 0.2018 sec.\n",
      "iter : 2400 || loc: 2.2766 || conf: 5.9677 || dom: 0.0015 || loss: 8.2458 ||\n",
      "\n",
      "Timer: 0.2017 sec.\n",
      "iter : 2410 || loc: 2.7553 || conf: 6.4395 || dom: 0.0014 || loss: 9.1962 ||\n",
      "\n",
      "Timer: 0.1997 sec.\n",
      "iter : 2420 || loc: 2.5504 || conf: 8.4944 || dom: 0.0036 || loss: 11.0484 ||\n",
      "\n",
      "Timer: 0.2077 sec.\n",
      "iter : 2430 || loc: 2.4511 || conf: 11.8666 || dom: 0.0016 || loss: 14.3194 ||\n",
      "\n",
      "Timer: 0.2152 sec.\n",
      "iter : 2440 || loc: 2.7900 || conf: 7.2385 || dom: 0.0017 || loss: 10.0303 ||\n",
      "\n",
      "Timer: 0.2041 sec.\n",
      "iter : 2450 || loc: 2.4198 || conf: 7.8985 || dom: 0.0010 || loss: 10.3194 ||\n",
      "\n",
      "Timer: 0.2077 sec.\n",
      "iter : 2460 || loc: 2.8111 || conf: 7.2061 || dom: 0.0017 || loss: 10.0189 ||\n",
      "\n",
      "Timer: 0.2035 sec.\n",
      "iter : 2470 || loc: 2.3969 || conf: 5.1424 || dom: 0.0013 || loss: 7.5407 ||\n",
      "\n",
      "Timer: 0.2068 sec.\n",
      "iter : 2480 || loc: 2.4093 || conf: 7.6450 || dom: 0.0014 || loss: 10.0557 ||\n",
      "\n",
      "Timer: 0.2095 sec.\n",
      "iter : 2490 || loc: 2.3861 || conf: 9.2571 || dom: 0.0013 || loss: 11.6445 ||\n",
      "\n",
      "Timer: 0.2065 sec.\n",
      "iter : 2500 || loc: 2.5441 || conf: 7.3108 || dom: 0.0014 || loss: 9.8562 ||\n",
      "\n",
      "Timer: 0.1970 sec.\n",
      "iter : 2510 || loc: 1.8356 || conf: 5.6343 || dom: 0.0023 || loss: 7.4722 ||\n",
      "\n",
      "Timer: 0.2039 sec.\n",
      "iter : 2520 || loc: 2.4182 || conf: 5.0664 || dom: 0.0014 || loss: 7.4859 ||\n",
      "\n",
      "Timer: 0.2003 sec.\n",
      "iter : 2530 || loc: 2.5871 || conf: 7.1626 || dom: 0.0009 || loss: 9.7506 ||\n",
      "\n",
      "Timer: 0.2152 sec.\n",
      "iter : 2540 || loc: 2.5973 || conf: 6.0034 || dom: 0.0009 || loss: 8.6016 ||\n",
      "\n",
      "Timer: 0.2040 sec.\n",
      "iter : 2550 || loc: 2.9789 || conf: 5.7196 || dom: 0.0016 || loss: 8.7001 ||\n",
      "\n",
      "Timer: 0.2127 sec.\n",
      "iter : 2560 || loc: 2.6872 || conf: 5.2059 || dom: 0.0012 || loss: 7.8944 ||\n",
      "\n",
      "Timer: 0.2092 sec.\n",
      "iter : 2570 || loc: 2.4370 || conf: 5.2316 || dom: 0.0015 || loss: 7.6701 ||\n",
      "\n",
      "Timer: 0.2055 sec.\n",
      "iter : 2580 || loc: 2.9135 || conf: 5.4337 || dom: 0.0017 || loss: 8.3489 ||\n",
      "\n",
      "Timer: 0.2041 sec.\n",
      "iter : 2590 || loc: 2.5414 || conf: 5.3889 || dom: 0.0010 || loss: 7.9313 ||\n",
      "\n",
      "Timer: 0.2131 sec.\n",
      "iter : 2600 || loc: 2.8153 || conf: 7.0836 || dom: 0.0014 || loss: 9.9003 ||\n",
      "\n",
      "Timer: 0.2025 sec.\n",
      "iter : 2610 || loc: 2.6895 || conf: 5.4041 || dom: 0.0017 || loss: 8.0953 ||\n",
      "\n",
      "Timer: 0.2150 sec.\n",
      "iter : 2620 || loc: 2.5944 || conf: 5.4383 || dom: 0.0011 || loss: 8.0338 ||\n",
      "\n",
      "Timer: 0.2043 sec.\n",
      "iter : 2630 || loc: 2.4377 || conf: 5.4032 || dom: 0.0024 || loss: 7.8433 ||\n",
      "\n",
      "Timer: 0.2031 sec.\n",
      "iter : 2640 || loc: 2.4840 || conf: 5.3750 || dom: 0.0015 || loss: 7.8604 ||\n",
      "\n",
      "Timer: 0.2045 sec.\n",
      "iter : 2650 || loc: 2.3440 || conf: 5.0604 || dom: 0.0018 || loss: 7.4062 ||\n",
      "\n",
      "Timer: 0.2025 sec.\n",
      "iter : 2660 || loc: 3.0691 || conf: 5.3512 || dom: 0.0011 || loss: 8.4214 ||\n",
      "\n",
      "Timer: 0.2011 sec.\n",
      "iter : 2670 || loc: 2.8387 || conf: 5.8054 || dom: 0.0011 || loss: 8.6452 ||\n",
      "\n",
      "Timer: 0.2060 sec.\n",
      "iter : 2680 || loc: 2.3127 || conf: 7.2035 || dom: 0.0013 || loss: 9.5175 ||\n",
      "\n",
      "Timer: 0.2028 sec.\n",
      "iter : 2690 || loc: 2.9367 || conf: 5.8434 || dom: 0.0011 || loss: 8.7813 ||\n",
      "\n",
      "Timer: 0.2039 sec.\n",
      "iter : 2700 || loc: 2.7969 || conf: 5.1573 || dom: 0.0012 || loss: 7.9554 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 2710 || loc: 2.5881 || conf: 5.5795 || dom: 0.0013 || loss: 8.1689 ||\n",
      "\n",
      "Timer: 0.1983 sec.\n",
      "iter : 2720 || loc: 2.5475 || conf: 5.1847 || dom: 0.0012 || loss: 7.7334 ||\n",
      "\n",
      "Timer: 0.2091 sec.\n",
      "iter : 2730 || loc: 2.9092 || conf: 5.4923 || dom: 0.0014 || loss: 8.4029 ||\n",
      "\n",
      "Timer: 0.2071 sec.\n",
      "iter : 2740 || loc: 2.6415 || conf: 6.5472 || dom: 0.0018 || loss: 9.1904 ||\n",
      "\n",
      "Timer: 0.2102 sec.\n",
      "iter : 2750 || loc: 2.1447 || conf: 4.5756 || dom: 0.0012 || loss: 6.7215 ||\n",
      "\n",
      "Timer: 0.1991 sec.\n",
      "iter : 2760 || loc: 2.4994 || conf: 5.2872 || dom: 0.0017 || loss: 7.7884 ||\n",
      "\n",
      "Timer: 0.2034 sec.\n",
      "iter : 2770 || loc: 2.7680 || conf: 6.9430 || dom: 0.0011 || loss: 9.7122 ||\n",
      "\n",
      "Timer: 0.2072 sec.\n",
      "iter : 2780 || loc: 2.3073 || conf: 4.4422 || dom: 0.0017 || loss: 6.7512 ||\n",
      "\n",
      "Timer: 0.2048 sec.\n",
      "iter : 2790 || loc: 2.7341 || conf: 5.1011 || dom: 0.0019 || loss: 7.8371 ||\n",
      "\n",
      "Timer: 0.2018 sec.\n",
      "iter : 2800 || loc: 2.4772 || conf: 5.9550 || dom: 0.0010 || loss: 8.4332 ||\n",
      "\n",
      "Timer: 0.2079 sec.\n",
      "iter : 2810 || loc: 2.4323 || conf: 5.1980 || dom: 0.0012 || loss: 7.6315 ||\n",
      "\n",
      "Timer: 0.2114 sec.\n",
      "iter : 2820 || loc: 2.2288 || conf: 5.4135 || dom: 0.0014 || loss: 7.6436 ||\n",
      "\n",
      "Timer: 0.2033 sec.\n",
      "iter : 2830 || loc: 2.0751 || conf: 5.2173 || dom: 0.0021 || loss: 7.2945 ||\n",
      "\n",
      "Timer: 0.2162 sec.\n",
      "iter : 2840 || loc: 2.3622 || conf: 5.4917 || dom: 0.0009 || loss: 7.8548 ||\n",
      "\n",
      "Timer: 0.2095 sec.\n",
      "iter : 2850 || loc: 1.9629 || conf: 5.1515 || dom: 0.0016 || loss: 7.1160 ||\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.2058 sec.\n",
      "iter : 2860 || loc: 2.5942 || conf: 6.0533 || dom: 0.0013 || loss: 8.6488 ||\n",
      "\n",
      "Timer: 0.2073 sec.\n",
      "iter : 2870 || loc: 2.6357 || conf: 6.2141 || dom: 0.0013 || loss: 8.8511 ||\n",
      "\n",
      "Timer: 0.2225 sec.\n",
      "iter : 2880 || loc: 2.6515 || conf: 5.4964 || dom: 0.0015 || loss: 8.1495 ||\n",
      "\n",
      "Timer: 0.2063 sec.\n",
      "iter : 2890 || loc: 2.0863 || conf: 5.4561 || dom: 0.0016 || loss: 7.5440 ||\n",
      "\n",
      "Timer: 0.2116 sec.\n",
      "iter : 2900 || loc: 2.3548 || conf: 6.0109 || dom: 0.0012 || loss: 8.3668 ||\n",
      "\n",
      "Timer: 0.2071 sec.\n",
      "iter : 2910 || loc: 2.0717 || conf: 4.8278 || dom: 0.0020 || loss: 6.9015 ||\n",
      "\n",
      "Timer: 0.2075 sec.\n",
      "iter : 2920 || loc: 2.8969 || conf: 5.8254 || dom: 0.0011 || loss: 8.7234 ||\n",
      "\n",
      "Timer: 0.2067 sec.\n",
      "iter : 2930 || loc: 2.5328 || conf: 5.2631 || dom: 0.0016 || loss: 7.7976 ||\n",
      "\n",
      "Timer: 0.2042 sec.\n",
      "iter : 2940 || loc: 2.4907 || conf: 4.5645 || dom: 0.0013 || loss: 7.0565 ||\n",
      "\n",
      "Timer: 0.2110 sec.\n",
      "iter : 2950 || loc: 2.2289 || conf: 4.9048 || dom: 0.0013 || loss: 7.1350 ||\n",
      "\n",
      "Timer: 0.2075 sec.\n",
      "iter : 2960 || loc: 2.8758 || conf: 7.3767 || dom: 0.0012 || loss: 10.2537 ||\n",
      "\n",
      "Timer: 0.2124 sec.\n",
      "iter : 2970 || loc: 3.1251 || conf: 6.0546 || dom: 0.0015 || loss: 9.1812 ||\n",
      "\n",
      "Timer: 0.2007 sec.\n",
      "iter : 2980 || loc: 2.7003 || conf: 5.7278 || dom: 0.0016 || loss: 8.4296 ||\n",
      "\n",
      "Timer: 0.2009 sec.\n",
      "iter : 2990 || loc: 3.0125 || conf: 7.6965 || dom: 0.0011 || loss: 10.7100 ||\n",
      "\n",
      "Timer: 0.2011 sec.\n",
      "iter : 3000 || loc: 2.6796 || conf: 6.2223 || dom: 0.0012 || loss: 8.9031 ||\n",
      "\n",
      "Timer: 0.2072 sec.\n",
      "iter : 3010 || loc: 2.3714 || conf: 6.0328 || dom: 0.0013 || loss: 8.4054 ||\n",
      "\n",
      "Timer: 0.2055 sec.\n",
      "iter : 3020 || loc: 2.4651 || conf: 5.2786 || dom: 0.0016 || loss: 7.7454 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 3030 || loc: 2.6143 || conf: 5.6950 || dom: 0.0012 || loss: 8.3104 ||\n",
      "\n",
      "Timer: 0.1997 sec.\n",
      "iter : 3040 || loc: 2.9327 || conf: 4.8847 || dom: 0.0016 || loss: 7.8189 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 3050 || loc: 2.2027 || conf: 5.8976 || dom: 0.0017 || loss: 8.1020 ||\n",
      "\n",
      "Timer: 0.2100 sec.\n",
      "iter : 3060 || loc: 1.8077 || conf: 4.1901 || dom: 0.0031 || loss: 6.0010 ||\n",
      "\n",
      "Timer: 0.2165 sec.\n",
      "iter : 3070 || loc: 2.5885 || conf: 5.5411 || dom: 0.0012 || loss: 8.1308 ||\n",
      "\n",
      "Timer: 0.2104 sec.\n",
      "iter : 3080 || loc: 2.7274 || conf: 7.4259 || dom: 0.0010 || loss: 10.1543 ||\n",
      "\n",
      "Timer: 0.2046 sec.\n",
      "iter : 3090 || loc: 2.4730 || conf: 5.8892 || dom: 0.0010 || loss: 8.3632 ||\n",
      "\n",
      "Timer: 0.2006 sec.\n",
      "iter : 3100 || loc: 3.0049 || conf: 4.8775 || dom: 0.0013 || loss: 7.8837 ||\n",
      "\n",
      "Timer: 0.2036 sec.\n",
      "iter : 3110 || loc: 2.7006 || conf: 7.2872 || dom: 0.0014 || loss: 9.9892 ||\n",
      "\n",
      "Timer: 0.2112 sec.\n",
      "iter : 3120 || loc: 2.6821 || conf: 5.0216 || dom: 0.0008 || loss: 7.7045 ||\n",
      "\n",
      "Timer: 0.1986 sec.\n",
      "iter : 3130 || loc: 2.9972 || conf: 5.1214 || dom: 0.0011 || loss: 8.1197 ||\n",
      "\n",
      "Timer: 0.2049 sec.\n",
      "iter : 3140 || loc: 2.2458 || conf: 5.5788 || dom: 0.0013 || loss: 7.8259 ||\n",
      "\n",
      "Timer: 0.2176 sec.\n",
      "iter : 3150 || loc: 2.5086 || conf: 5.9459 || dom: 0.0012 || loss: 8.4556 ||\n",
      "\n",
      "Timer: 0.2031 sec.\n",
      "iter : 3160 || loc: 2.2352 || conf: 4.3550 || dom: 0.0014 || loss: 6.5916 ||\n",
      "\n",
      "Timer: 0.2071 sec.\n",
      "iter : 3170 || loc: 2.3417 || conf: 5.7146 || dom: 0.0009 || loss: 8.0573 ||\n",
      "\n",
      "Timer: 0.2064 sec.\n",
      "iter : 3180 || loc: 2.0219 || conf: 5.2023 || dom: 0.0018 || loss: 7.2259 ||\n",
      "\n",
      "Timer: 0.2052 sec.\n",
      "iter : 3190 || loc: 2.0570 || conf: 5.9111 || dom: 0.0010 || loss: 7.9690 ||\n",
      "\n",
      "Timer: 0.2062 sec.\n",
      "iter : 3200 || loc: 2.5512 || conf: 4.4877 || dom: 0.0016 || loss: 7.0405 ||\n",
      "\n",
      "Timer: 0.2136 sec.\n",
      "iter : 3210 || loc: 2.2940 || conf: 4.7163 || dom: 0.0016 || loss: 7.0120 ||\n",
      "\n",
      "Timer: 0.2073 sec.\n",
      "iter : 3220 || loc: 3.0370 || conf: 4.9769 || dom: 0.0013 || loss: 8.0153 ||\n",
      "\n",
      "Timer: 0.1993 sec.\n",
      "iter : 3230 || loc: 2.1895 || conf: 4.6314 || dom: 0.0018 || loss: 6.8227 ||\n",
      "\n",
      "Timer: 0.2010 sec.\n",
      "iter : 3240 || loc: 2.4155 || conf: 5.9929 || dom: 0.0016 || loss: 8.4100 ||\n",
      "\n",
      "Timer: 0.1953 sec.\n",
      "iter : 3250 || loc: 2.6264 || conf: 4.6836 || dom: 0.0012 || loss: 7.3112 ||\n",
      "\n",
      "Timer: 0.1985 sec.\n",
      "iter : 3260 || loc: 2.2798 || conf: 4.2110 || dom: 0.0016 || loss: 6.4924 ||\n",
      "\n",
      "Timer: 0.2203 sec.\n",
      "iter : 3270 || loc: 2.3639 || conf: 5.6388 || dom: 0.0010 || loss: 8.0037 ||\n",
      "\n",
      "Timer: 0.2119 sec.\n",
      "iter : 3280 || loc: 2.2224 || conf: 4.7564 || dom: 0.0022 || loss: 6.9809 ||\n",
      "\n",
      "Timer: 0.2025 sec.\n",
      "iter : 3290 || loc: 2.3498 || conf: 5.4518 || dom: 0.0015 || loss: 7.8031 ||\n",
      "\n",
      "Timer: 0.2093 sec.\n",
      "iter : 3300 || loc: 3.0819 || conf: 4.6607 || dom: 0.0016 || loss: 7.7442 ||\n",
      "\n",
      "Timer: 0.2053 sec.\n",
      "iter : 3310 || loc: 2.9837 || conf: 5.4449 || dom: 0.0013 || loss: 8.4299 ||\n",
      "\n",
      "Timer: 0.2163 sec.\n",
      "iter : 3320 || loc: 2.4655 || conf: 4.5207 || dom: 0.0013 || loss: 6.9874 ||\n",
      "\n",
      "Timer: 0.2034 sec.\n",
      "iter : 3330 || loc: 2.4746 || conf: 4.9066 || dom: 0.0013 || loss: 7.3825 ||\n",
      "\n",
      "Timer: 0.2024 sec.\n",
      "iter : 3340 || loc: 2.8788 || conf: 6.3131 || dom: 0.0016 || loss: 9.1935 ||\n",
      "\n",
      "Timer: 0.2069 sec.\n",
      "iter : 3350 || loc: 2.4295 || conf: 4.3346 || dom: 0.0012 || loss: 6.7653 ||\n",
      "\n",
      "Timer: 0.2133 sec.\n",
      "iter : 3360 || loc: 2.5261 || conf: 5.9461 || dom: 0.0008 || loss: 8.4731 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 3370 || loc: 2.6896 || conf: 5.5759 || dom: 0.0015 || loss: 8.2669 ||\n",
      "\n",
      "Timer: 0.2093 sec.\n",
      "iter : 3380 || loc: 2.1659 || conf: 5.7557 || dom: 0.0009 || loss: 7.9225 ||\n",
      "\n",
      "Timer: 0.2002 sec.\n",
      "iter : 3390 || loc: 2.1762 || conf: 4.2417 || dom: 0.0011 || loss: 6.4190 ||\n",
      "\n",
      "Timer: 0.2033 sec.\n",
      "iter : 3400 || loc: 2.5342 || conf: 5.1003 || dom: 0.0011 || loss: 7.6356 ||\n",
      "\n",
      "Timer: 0.1992 sec.\n",
      "iter : 3410 || loc: 2.5587 || conf: 4.6515 || dom: 0.0011 || loss: 7.2114 ||\n",
      "\n",
      "Timer: 0.2061 sec.\n",
      "iter : 3420 || loc: 2.2136 || conf: 4.3775 || dom: 0.0018 || loss: 6.5929 ||\n",
      "\n",
      "Timer: 0.2046 sec.\n",
      "iter : 3430 || loc: 2.7473 || conf: 4.8981 || dom: 0.0011 || loss: 7.6465 ||\n",
      "\n",
      "Timer: 0.2045 sec.\n",
      "iter : 3440 || loc: 2.9151 || conf: 7.2916 || dom: 0.0009 || loss: 10.2075 ||\n",
      "\n",
      "Timer: 0.2061 sec.\n",
      "iter : 3450 || loc: 2.4517 || conf: 4.6860 || dom: 0.0014 || loss: 7.1390 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 3460 || loc: 2.1270 || conf: 6.3481 || dom: 0.0020 || loss: 8.4771 ||\n",
      "\n",
      "Timer: 0.2178 sec.\n",
      "iter : 3470 || loc: 2.5246 || conf: 4.9088 || dom: 0.0020 || loss: 7.4354 ||\n",
      "\n",
      "Timer: 0.2102 sec.\n",
      "iter : 3480 || loc: 2.8936 || conf: 5.2537 || dom: 0.0013 || loss: 8.1486 ||\n",
      "\n",
      "Timer: 0.1977 sec.\n",
      "iter : 3490 || loc: 2.3151 || conf: 5.3877 || dom: 0.0014 || loss: 7.7042 ||\n",
      "\n",
      "Timer: 0.2071 sec.\n",
      "iter : 3500 || loc: 2.1880 || conf: 4.2075 || dom: 0.0015 || loss: 6.3970 ||\n",
      "\n",
      "Timer: 0.2056 sec.\n",
      "iter : 3510 || loc: 1.8311 || conf: 4.9881 || dom: 0.0025 || loss: 6.8217 ||\n",
      "\n",
      "Timer: 0.2068 sec.\n",
      "iter : 3520 || loc: 2.1934 || conf: 4.9217 || dom: 0.0020 || loss: 7.1171 ||\n",
      "\n",
      "Timer: 0.2073 sec.\n",
      "iter : 3530 || loc: 3.0148 || conf: 6.8878 || dom: 0.0010 || loss: 9.9035 ||\n",
      "\n",
      "Timer: 0.2094 sec.\n",
      "iter : 3540 || loc: 2.3564 || conf: 7.4728 || dom: 0.0012 || loss: 9.8303 ||\n",
      "\n",
      "Timer: 0.2013 sec.\n",
      "iter : 3550 || loc: 2.2030 || conf: 5.0868 || dom: 0.0017 || loss: 7.2916 ||\n",
      "\n",
      "Timer: 0.2120 sec.\n",
      "iter : 3560 || loc: 2.7271 || conf: 5.5870 || dom: 0.0007 || loss: 8.3148 ||\n",
      "\n",
      "Timer: 0.2047 sec.\n",
      "iter : 3570 || loc: 2.2198 || conf: 4.4083 || dom: 0.0011 || loss: 6.6292 ||\n",
      "\n",
      "Timer: 0.2052 sec.\n",
      "iter : 3580 || loc: 2.4117 || conf: 5.9436 || dom: 0.0014 || loss: 8.3567 ||\n",
      "\n",
      "Timer: 0.2144 sec.\n",
      "iter : 3590 || loc: 2.5771 || conf: 4.0492 || dom: 0.0011 || loss: 6.6273 ||\n",
      "\n",
      "Timer: 0.2016 sec.\n",
      "iter : 3600 || loc: 2.0839 || conf: 5.2779 || dom: 0.0020 || loss: 7.3638 ||\n",
      "\n",
      "Timer: 0.2056 sec.\n",
      "iter : 3610 || loc: 2.6934 || conf: 4.1069 || dom: 0.0011 || loss: 6.8014 ||\n",
      "\n",
      "Timer: 0.2136 sec.\n",
      "iter : 3620 || loc: 2.4165 || conf: 5.0031 || dom: 0.0016 || loss: 7.4212 ||\n",
      "\n",
      "Timer: 0.2085 sec.\n",
      "iter : 3630 || loc: 2.2522 || conf: 4.9570 || dom: 0.0015 || loss: 7.2107 ||\n",
      "\n",
      "Timer: 0.2173 sec.\n",
      "iter : 3640 || loc: 2.6368 || conf: 5.6230 || dom: 0.0011 || loss: 8.2608 ||\n",
      "\n",
      "Timer: 0.2021 sec.\n",
      "iter : 3650 || loc: 2.1235 || conf: 4.2174 || dom: 0.0021 || loss: 6.3430 ||\n",
      "\n",
      "Timer: 0.1948 sec.\n",
      "iter : 3660 || loc: 3.0537 || conf: 4.3887 || dom: 0.0016 || loss: 7.4440 ||\n",
      "\n",
      "Timer: 0.2061 sec.\n",
      "iter : 3670 || loc: 2.4167 || conf: 4.2549 || dom: 0.0012 || loss: 6.6728 ||\n",
      "\n",
      "Timer: 0.2053 sec.\n",
      "iter : 3680 || loc: 2.1003 || conf: 5.0611 || dom: 0.0019 || loss: 7.1633 ||\n",
      "\n",
      "Timer: 0.2102 sec.\n",
      "iter : 3690 || loc: 2.2469 || conf: 4.3143 || dom: 0.0013 || loss: 6.5625 ||\n",
      "\n",
      "Timer: 0.2088 sec.\n",
      "iter : 3700 || loc: 2.4028 || conf: 4.9880 || dom: 0.0010 || loss: 7.3918 ||\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.2044 sec.\n",
      "iter : 3710 || loc: 2.2189 || conf: 4.6975 || dom: 0.0012 || loss: 6.9177 ||\n",
      "\n",
      "Timer: 0.2015 sec.\n",
      "iter : 3720 || loc: 2.8690 || conf: 4.9815 || dom: 0.0012 || loss: 7.8518 ||\n",
      "\n",
      "Timer: 0.2141 sec.\n",
      "iter : 3730 || loc: 2.2574 || conf: 5.5723 || dom: 0.0012 || loss: 7.8310 ||\n",
      "\n",
      "Timer: 0.2056 sec.\n",
      "iter : 3740 || loc: 3.0043 || conf: 4.1275 || dom: 0.0021 || loss: 7.1338 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 3750 || loc: 2.1645 || conf: 4.3666 || dom: 0.0017 || loss: 6.5328 ||\n",
      "\n",
      "Timer: 0.2029 sec.\n",
      "iter : 3760 || loc: 2.1021 || conf: 4.4766 || dom: 0.0014 || loss: 6.5801 ||\n",
      "\n",
      "Timer: 0.1993 sec.\n",
      "iter : 3770 || loc: 1.9441 || conf: 4.4447 || dom: 0.0013 || loss: 6.3901 ||\n",
      "\n",
      "Timer: 0.2065 sec.\n",
      "iter : 3780 || loc: 2.8262 || conf: 5.0252 || dom: 0.0013 || loss: 7.8526 ||\n",
      "\n",
      "Timer: 0.2012 sec.\n",
      "iter : 3790 || loc: 1.9196 || conf: 5.0874 || dom: 0.0013 || loss: 7.0082 ||\n",
      "\n",
      "Timer: 0.2155 sec.\n",
      "iter : 3800 || loc: 2.5124 || conf: 5.0619 || dom: 0.0022 || loss: 7.5765 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 3810 || loc: 2.0583 || conf: 5.1513 || dom: 0.0020 || loss: 7.2116 ||\n",
      "\n",
      "Timer: 0.2030 sec.\n",
      "iter : 3820 || loc: 2.5939 || conf: 5.3062 || dom: 0.0010 || loss: 7.9011 ||\n",
      "\n",
      "Timer: 0.2143 sec.\n",
      "iter : 3830 || loc: 2.5660 || conf: 5.2313 || dom: 0.0012 || loss: 7.7985 ||\n",
      "\n",
      "Timer: 0.2035 sec.\n",
      "iter : 3840 || loc: 2.6660 || conf: 4.9683 || dom: 0.0008 || loss: 7.6351 ||\n",
      "\n",
      "Timer: 0.2125 sec.\n",
      "iter : 3850 || loc: 2.5473 || conf: 4.7984 || dom: 0.0010 || loss: 7.3467 ||\n",
      "\n",
      "Timer: 0.2163 sec.\n",
      "iter : 3860 || loc: 2.2670 || conf: 5.1708 || dom: 0.0010 || loss: 7.4389 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 3870 || loc: 2.2358 || conf: 4.4674 || dom: 0.0007 || loss: 6.7039 ||\n",
      "\n",
      "Timer: 0.2015 sec.\n",
      "iter : 3880 || loc: 2.0406 || conf: 4.7945 || dom: 0.0011 || loss: 6.8362 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 3890 || loc: 2.4865 || conf: 5.1973 || dom: 0.0013 || loss: 7.6851 ||\n",
      "\n",
      "Timer: 0.2097 sec.\n",
      "iter : 3900 || loc: 3.1532 || conf: 5.3433 || dom: 0.0013 || loss: 8.4979 ||\n",
      "\n",
      "Timer: 0.2064 sec.\n",
      "iter : 3910 || loc: 2.2499 || conf: 4.3836 || dom: 0.0013 || loss: 6.6348 ||\n",
      "\n",
      "Timer: 0.2111 sec.\n",
      "iter : 3920 || loc: 2.8224 || conf: 4.6231 || dom: 0.0015 || loss: 7.4471 ||\n",
      "\n",
      "Timer: 0.2032 sec.\n",
      "iter : 3930 || loc: 2.2152 || conf: 4.1899 || dom: 0.0007 || loss: 6.4058 ||\n",
      "\n",
      "Timer: 0.2038 sec.\n",
      "iter : 3940 || loc: 3.0229 || conf: 5.5180 || dom: 0.0015 || loss: 8.5424 ||\n",
      "\n",
      "Timer: 0.1960 sec.\n",
      "iter : 3950 || loc: 1.9262 || conf: 4.5970 || dom: 0.0023 || loss: 6.5255 ||\n",
      "\n",
      "Timer: 0.1997 sec.\n",
      "iter : 3960 || loc: 2.6645 || conf: 5.8554 || dom: 0.0015 || loss: 8.5214 ||\n",
      "\n",
      "Timer: 0.2072 sec.\n",
      "iter : 3970 || loc: 1.9259 || conf: 4.0244 || dom: 0.0015 || loss: 5.9518 ||\n",
      "\n",
      "Timer: 0.2006 sec.\n",
      "iter : 3980 || loc: 2.3395 || conf: 4.3276 || dom: 0.0013 || loss: 6.6683 ||\n",
      "\n",
      "Timer: 0.2077 sec.\n",
      "iter : 3990 || loc: 2.0868 || conf: 4.8359 || dom: 0.0012 || loss: 6.9239 ||\n",
      "\n",
      "Timer: 0.2003 sec.\n",
      "iter : 4000 || loc: 1.8508 || conf: 4.4443 || dom: 0.0016 || loss: 6.2967 ||\n",
      "\n",
      "Saving state, iter: 4000\n",
      "Timer: 0.2102 sec.\n",
      "iter : 4010 || loc: 2.1112 || conf: 4.1383 || dom: 0.0012 || loss: 6.2507 ||\n",
      "\n",
      "Timer: 0.2089 sec.\n",
      "iter : 4020 || loc: 2.3715 || conf: 5.3823 || dom: 0.0010 || loss: 7.7548 ||\n",
      "\n",
      "Timer: 0.2007 sec.\n",
      "iter : 4030 || loc: 2.0758 || conf: 5.0228 || dom: 0.0017 || loss: 7.1003 ||\n",
      "\n",
      "Timer: 0.2206 sec.\n",
      "iter : 4040 || loc: 2.5668 || conf: 4.2244 || dom: 0.0014 || loss: 6.7925 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 4050 || loc: 2.5603 || conf: 5.2040 || dom: 0.0009 || loss: 7.7652 ||\n",
      "\n",
      "Timer: 0.2008 sec.\n",
      "iter : 4060 || loc: 1.5961 || conf: 4.5789 || dom: 0.0017 || loss: 6.1767 ||\n",
      "\n",
      "Timer: 0.2076 sec.\n",
      "iter : 4070 || loc: 2.6617 || conf: 4.4634 || dom: 0.0010 || loss: 7.1262 ||\n",
      "\n",
      "Timer: 0.2073 sec.\n",
      "iter : 4080 || loc: 2.7467 || conf: 4.4210 || dom: 0.0013 || loss: 7.1690 ||\n",
      "\n",
      "Timer: 0.2102 sec.\n",
      "iter : 4090 || loc: 2.4403 || conf: 4.7538 || dom: 0.0014 || loss: 7.1955 ||\n",
      "\n",
      "Timer: 0.2242 sec.\n",
      "iter : 4100 || loc: 2.5832 || conf: 4.9690 || dom: 0.0011 || loss: 7.5533 ||\n",
      "\n",
      "Timer: 0.2023 sec.\n",
      "iter : 4110 || loc: 2.1882 || conf: 4.8062 || dom: 0.0012 || loss: 6.9955 ||\n",
      "\n",
      "Timer: 0.2025 sec.\n",
      "iter : 4120 || loc: 2.5216 || conf: 5.0172 || dom: 0.0017 || loss: 7.5404 ||\n",
      "\n",
      "Timer: 0.2017 sec.\n",
      "iter : 4130 || loc: 2.2448 || conf: 4.8952 || dom: 0.0007 || loss: 7.1407 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 4140 || loc: 3.1590 || conf: 6.2280 || dom: 0.0024 || loss: 9.3895 ||\n",
      "\n",
      "Timer: 0.2023 sec.\n",
      "iter : 4150 || loc: 2.6918 || conf: 4.1916 || dom: 0.0013 || loss: 6.8848 ||\n",
      "\n",
      "Timer: 0.2068 sec.\n",
      "iter : 4160 || loc: 2.3741 || conf: 4.2675 || dom: 0.0012 || loss: 6.6429 ||\n",
      "\n",
      "Timer: 0.1992 sec.\n",
      "iter : 4170 || loc: 2.2535 || conf: 4.3305 || dom: 0.0011 || loss: 6.5851 ||\n",
      "\n",
      "Timer: 0.2047 sec.\n",
      "iter : 4180 || loc: 2.2517 || conf: 3.8035 || dom: 0.0015 || loss: 6.0567 ||\n",
      "\n",
      "Timer: 0.2164 sec.\n",
      "iter : 4190 || loc: 2.3535 || conf: 4.3241 || dom: 0.0012 || loss: 6.6788 ||\n",
      "\n",
      "Timer: 0.2005 sec.\n",
      "iter : 4200 || loc: 2.4362 || conf: 4.5035 || dom: 0.0010 || loss: 6.9406 ||\n",
      "\n",
      "Timer: 0.2000 sec.\n",
      "iter : 4210 || loc: 2.2692 || conf: 4.4786 || dom: 0.0011 || loss: 6.7489 ||\n",
      "\n",
      "Timer: 0.2072 sec.\n",
      "iter : 4220 || loc: 2.2669 || conf: 5.0322 || dom: 0.0010 || loss: 7.3001 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 4230 || loc: 2.2805 || conf: 4.7947 || dom: 0.0011 || loss: 7.0763 ||\n",
      "\n",
      "Timer: 0.2011 sec.\n",
      "iter : 4240 || loc: 2.2949 || conf: 5.0330 || dom: 0.0008 || loss: 7.3286 ||\n",
      "\n",
      "Timer: 0.2098 sec.\n",
      "iter : 4250 || loc: 2.4227 || conf: 5.9046 || dom: 0.0014 || loss: 8.3286 ||\n",
      "\n",
      "Timer: 0.2129 sec.\n",
      "iter : 4260 || loc: 2.3047 || conf: 3.8504 || dom: 0.0010 || loss: 6.1561 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 4270 || loc: 2.0765 || conf: 5.2052 || dom: 0.0011 || loss: 7.2827 ||\n",
      "\n",
      "Timer: 0.1990 sec.\n",
      "iter : 4280 || loc: 2.1993 || conf: 4.1620 || dom: 0.0013 || loss: 6.3626 ||\n",
      "\n",
      "Timer: 0.2063 sec.\n",
      "iter : 4290 || loc: 2.7988 || conf: 4.6493 || dom: 0.0011 || loss: 7.4491 ||\n",
      "\n",
      "Timer: 0.2084 sec.\n",
      "iter : 4300 || loc: 1.9533 || conf: 4.2516 || dom: 0.0008 || loss: 6.2058 ||\n",
      "\n",
      "Timer: 0.2088 sec.\n",
      "iter : 4310 || loc: 1.9239 || conf: 4.5556 || dom: 0.0012 || loss: 6.4807 ||\n",
      "\n",
      "Timer: 0.2126 sec.\n",
      "iter : 4320 || loc: 2.0547 || conf: 4.0679 || dom: 0.0009 || loss: 6.1235 ||\n",
      "\n",
      "Timer: 0.2041 sec.\n",
      "iter : 4330 || loc: 2.2725 || conf: 5.0451 || dom: 0.0018 || loss: 7.3194 ||\n",
      "\n",
      "Timer: 0.2040 sec.\n",
      "iter : 4340 || loc: 2.5465 || conf: 3.6824 || dom: 0.0013 || loss: 6.2303 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 4350 || loc: 2.5343 || conf: 4.8692 || dom: 0.0010 || loss: 7.4045 ||\n",
      "\n",
      "Timer: 0.2096 sec.\n",
      "iter : 4360 || loc: 2.0569 || conf: 4.9876 || dom: 0.0011 || loss: 7.0457 ||\n",
      "\n",
      "Timer: 0.2038 sec.\n",
      "iter : 4370 || loc: 2.3609 || conf: 4.2493 || dom: 0.0009 || loss: 6.6111 ||\n",
      "\n",
      "Timer: 0.2092 sec.\n",
      "iter : 4380 || loc: 2.1956 || conf: 4.1573 || dom: 0.0011 || loss: 6.3540 ||\n",
      "\n",
      "Timer: 0.2028 sec.\n",
      "iter : 4390 || loc: 2.3338 || conf: 4.5484 || dom: 0.0017 || loss: 6.8839 ||\n",
      "\n",
      "Timer: 0.1966 sec.\n",
      "iter : 4400 || loc: 2.5689 || conf: 5.0314 || dom: 0.0016 || loss: 7.6019 ||\n",
      "\n",
      "Timer: 0.1993 sec.\n",
      "iter : 4410 || loc: 2.1122 || conf: 3.8224 || dom: 0.0011 || loss: 5.9357 ||\n",
      "\n",
      "Timer: 0.2042 sec.\n",
      "iter : 4420 || loc: 2.6607 || conf: 5.3057 || dom: 0.0023 || loss: 7.9687 ||\n",
      "\n",
      "Timer: 0.2081 sec.\n",
      "iter : 4430 || loc: 2.3744 || conf: 4.3613 || dom: 0.0012 || loss: 6.7369 ||\n",
      "\n",
      "Timer: 0.1966 sec.\n",
      "iter : 4440 || loc: 2.3873 || conf: 4.5804 || dom: 0.0012 || loss: 6.9688 ||\n",
      "\n",
      "Timer: 0.2045 sec.\n",
      "iter : 4450 || loc: 2.1239 || conf: 4.3042 || dom: 0.0011 || loss: 6.4292 ||\n",
      "\n",
      "Timer: 0.2053 sec.\n",
      "iter : 4460 || loc: 2.0935 || conf: 4.8929 || dom: 0.0015 || loss: 6.9879 ||\n",
      "\n",
      "Timer: 0.2071 sec.\n",
      "iter : 4470 || loc: 2.2461 || conf: 4.1360 || dom: 0.0012 || loss: 6.3833 ||\n",
      "\n",
      "Timer: 0.1991 sec.\n",
      "iter : 4480 || loc: 2.5735 || conf: 3.8983 || dom: 0.0012 || loss: 6.4729 ||\n",
      "\n",
      "Timer: 0.2176 sec.\n",
      "iter : 4490 || loc: 2.7376 || conf: 4.5998 || dom: 0.0024 || loss: 7.3398 ||\n",
      "\n",
      "Timer: 0.2131 sec.\n",
      "iter : 4500 || loc: 2.5234 || conf: 5.0182 || dom: 0.0011 || loss: 7.5427 ||\n",
      "\n",
      "Timer: 0.2018 sec.\n",
      "iter : 4510 || loc: 2.2113 || conf: 4.3529 || dom: 0.0012 || loss: 6.5653 ||\n",
      "\n",
      "Timer: 0.2096 sec.\n",
      "iter : 4520 || loc: 2.1248 || conf: 4.6307 || dom: 0.0009 || loss: 6.7564 ||\n",
      "\n",
      "Timer: 0.2002 sec.\n",
      "iter : 4530 || loc: 2.2492 || conf: 5.0378 || dom: 0.0006 || loss: 7.2877 ||\n",
      "\n",
      "Timer: 0.2090 sec.\n",
      "iter : 4540 || loc: 2.4862 || conf: 4.1732 || dom: 0.0014 || loss: 6.6607 ||\n",
      "\n",
      "Timer: 0.2071 sec.\n",
      "iter : 4550 || loc: 3.1028 || conf: 4.3652 || dom: 0.0012 || loss: 7.4692 ||\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.2072 sec.\n",
      "iter : 4560 || loc: 2.5865 || conf: 4.0510 || dom: 0.0007 || loss: 6.6382 ||\n",
      "\n",
      "Timer: 0.2106 sec.\n",
      "iter : 4570 || loc: 2.3506 || conf: 4.5393 || dom: 0.0012 || loss: 6.8911 ||\n",
      "\n",
      "Timer: 0.1976 sec.\n",
      "iter : 4580 || loc: 2.2670 || conf: 4.3605 || dom: 0.0009 || loss: 6.6285 ||\n",
      "\n",
      "Timer: 0.2073 sec.\n",
      "iter : 4590 || loc: 2.6719 || conf: 4.8541 || dom: 0.0010 || loss: 7.5270 ||\n",
      "\n",
      "Timer: 0.2015 sec.\n",
      "iter : 4600 || loc: 2.2645 || conf: 4.1626 || dom: 0.0007 || loss: 6.4278 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 4610 || loc: 2.0869 || conf: 5.0770 || dom: 0.0011 || loss: 7.1650 ||\n",
      "\n",
      "Timer: 0.2049 sec.\n",
      "iter : 4620 || loc: 1.9658 || conf: 4.5106 || dom: 0.0014 || loss: 6.4778 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 4630 || loc: 2.2277 || conf: 4.4819 || dom: 0.0010 || loss: 6.7107 ||\n",
      "\n",
      "Timer: 0.1985 sec.\n",
      "iter : 4640 || loc: 1.9925 || conf: 4.0222 || dom: 0.0009 || loss: 6.0156 ||\n",
      "\n",
      "Timer: 0.2034 sec.\n",
      "iter : 4650 || loc: 2.3580 || conf: 4.8136 || dom: 0.0009 || loss: 7.1726 ||\n",
      "\n",
      "Timer: 0.1959 sec.\n",
      "iter : 4660 || loc: 2.6245 || conf: 4.4302 || dom: 0.0010 || loss: 7.0557 ||\n",
      "\n",
      "Timer: 0.1997 sec.\n",
      "iter : 4670 || loc: 2.8685 || conf: 4.4970 || dom: 0.0016 || loss: 7.3671 ||\n",
      "\n",
      "Timer: 0.2012 sec.\n",
      "iter : 4680 || loc: 1.8319 || conf: 4.4266 || dom: 0.0024 || loss: 6.2609 ||\n",
      "\n",
      "Timer: 0.2076 sec.\n",
      "iter : 4690 || loc: 2.7073 || conf: 4.3918 || dom: 0.0014 || loss: 7.1005 ||\n",
      "\n",
      "Timer: 0.2061 sec.\n",
      "iter : 4700 || loc: 2.0017 || conf: 4.9245 || dom: 0.0017 || loss: 6.9279 ||\n",
      "\n",
      "Timer: 0.2033 sec.\n",
      "iter : 4710 || loc: 2.3186 || conf: 4.6317 || dom: 0.0008 || loss: 6.9510 ||\n",
      "\n",
      "Timer: 0.2121 sec.\n",
      "iter : 4720 || loc: 2.4448 || conf: 5.0957 || dom: 0.0011 || loss: 7.5416 ||\n",
      "\n",
      "Timer: 0.2084 sec.\n",
      "iter : 4730 || loc: 1.7726 || conf: 4.6042 || dom: 0.0013 || loss: 6.3781 ||\n",
      "\n",
      "Timer: 0.2136 sec.\n",
      "iter : 4740 || loc: 1.7415 || conf: 4.7785 || dom: 0.0015 || loss: 6.5215 ||\n",
      "\n",
      "Timer: 0.2160 sec.\n",
      "iter : 4750 || loc: 2.5795 || conf: 3.9661 || dom: 0.0013 || loss: 6.5469 ||\n",
      "\n",
      "Timer: 0.2087 sec.\n",
      "iter : 4760 || loc: 1.9742 || conf: 3.7233 || dom: 0.0011 || loss: 5.6986 ||\n",
      "\n",
      "Timer: 0.2046 sec.\n",
      "iter : 4770 || loc: 1.6869 || conf: 4.2920 || dom: 0.0009 || loss: 5.9798 ||\n",
      "\n",
      "Timer: 0.2127 sec.\n",
      "iter : 4780 || loc: 1.9832 || conf: 4.4480 || dom: 0.0014 || loss: 6.4326 ||\n",
      "\n",
      "Timer: 0.2068 sec.\n",
      "iter : 4790 || loc: 2.0031 || conf: 4.2068 || dom: 0.0010 || loss: 6.2109 ||\n",
      "\n",
      "Timer: 0.2108 sec.\n",
      "iter : 4800 || loc: 1.9440 || conf: 4.7687 || dom: 0.0015 || loss: 6.7141 ||\n",
      "\n",
      "Timer: 0.2013 sec.\n",
      "iter : 4810 || loc: 2.2786 || conf: 4.7853 || dom: 0.0013 || loss: 7.0651 ||\n",
      "\n",
      "Timer: 0.2070 sec.\n",
      "iter : 4820 || loc: 2.8685 || conf: 4.7016 || dom: 0.0016 || loss: 7.5718 ||\n",
      "\n",
      "Timer: 0.2018 sec.\n",
      "iter : 4830 || loc: 2.3938 || conf: 4.5329 || dom: 0.0014 || loss: 6.9280 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 4840 || loc: 2.2717 || conf: 3.7134 || dom: 0.0010 || loss: 5.9861 ||\n",
      "\n",
      "Timer: 0.2031 sec.\n",
      "iter : 4850 || loc: 2.3333 || conf: 4.6498 || dom: 0.0012 || loss: 6.9843 ||\n",
      "\n",
      "Timer: 0.2108 sec.\n",
      "iter : 4860 || loc: 1.9592 || conf: 3.8662 || dom: 0.0017 || loss: 5.8270 ||\n",
      "\n",
      "Timer: 0.2062 sec.\n",
      "iter : 4870 || loc: 2.1315 || conf: 4.0499 || dom: 0.0010 || loss: 6.1824 ||\n",
      "\n",
      "Timer: 0.1983 sec.\n",
      "iter : 4880 || loc: 2.1873 || conf: 4.4542 || dom: 0.0007 || loss: 6.6422 ||\n",
      "\n",
      "Timer: 0.2084 sec.\n",
      "iter : 4890 || loc: 1.9139 || conf: 4.3904 || dom: 0.0011 || loss: 6.3054 ||\n",
      "\n",
      "Timer: 0.2207 sec.\n",
      "iter : 4900 || loc: 2.3834 || conf: 4.6269 || dom: 0.0018 || loss: 7.0121 ||\n",
      "\n",
      "Timer: 0.2050 sec.\n",
      "iter : 4910 || loc: 2.0405 || conf: 4.5935 || dom: 0.0009 || loss: 6.6349 ||\n",
      "\n",
      "Timer: 0.2073 sec.\n",
      "iter : 4920 || loc: 2.9667 || conf: 4.3754 || dom: 0.0012 || loss: 7.3434 ||\n",
      "\n",
      "Timer: 0.2076 sec.\n",
      "iter : 4930 || loc: 1.8767 || conf: 4.4548 || dom: 0.0015 || loss: 6.3331 ||\n",
      "\n",
      "Timer: 0.1999 sec.\n",
      "iter : 4940 || loc: 2.1648 || conf: 4.4564 || dom: 0.0017 || loss: 6.6229 ||\n",
      "\n",
      "Timer: 0.2152 sec.\n",
      "iter : 4950 || loc: 2.1522 || conf: 4.9114 || dom: 0.0012 || loss: 7.0649 ||\n",
      "\n",
      "Timer: 0.2037 sec.\n",
      "iter : 4960 || loc: 2.0180 || conf: 4.3599 || dom: 0.0017 || loss: 6.3796 ||\n",
      "\n",
      "Timer: 0.1985 sec.\n",
      "iter : 4970 || loc: 2.4123 || conf: 4.1190 || dom: 0.0009 || loss: 6.5321 ||\n",
      "\n",
      "Timer: 0.2003 sec.\n",
      "iter : 4980 || loc: 1.8835 || conf: 4.6797 || dom: 0.0014 || loss: 6.5646 ||\n",
      "\n",
      "Timer: 0.1996 sec.\n",
      "iter : 4990 || loc: 2.8102 || conf: 4.6233 || dom: 0.0015 || loss: 7.4350 ||\n",
      "\n",
      "Timer: 0.2070 sec.\n",
      "iter : 5000 || loc: 2.3769 || conf: 4.5652 || dom: 0.0018 || loss: 6.9440 ||\n",
      "\n",
      "Timer: 0.2102 sec.\n",
      "iter : 5010 || loc: 2.4911 || conf: 4.2375 || dom: 0.0020 || loss: 6.7306 ||\n",
      "\n",
      "Timer: 0.2011 sec.\n",
      "iter : 5020 || loc: 1.8309 || conf: 4.1919 || dom: 0.0014 || loss: 6.0242 ||\n",
      "\n",
      "Timer: 0.1993 sec.\n",
      "iter : 5030 || loc: 2.0515 || conf: 4.1851 || dom: 0.0011 || loss: 6.2377 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 5040 || loc: 2.3400 || conf: 3.8755 || dom: 0.0012 || loss: 6.2166 ||\n",
      "\n",
      "Timer: 0.2114 sec.\n",
      "iter : 5050 || loc: 2.5095 || conf: 4.3999 || dom: 0.0021 || loss: 6.9115 ||\n",
      "\n",
      "Timer: 0.2043 sec.\n",
      "iter : 5060 || loc: 2.0952 || conf: 4.8310 || dom: 0.0015 || loss: 6.9277 ||\n",
      "\n",
      "Timer: 0.2107 sec.\n",
      "iter : 5070 || loc: 2.2548 || conf: 4.6629 || dom: 0.0016 || loss: 6.9194 ||\n",
      "\n",
      "Timer: 0.2028 sec.\n",
      "iter : 5080 || loc: 2.2505 || conf: 4.1851 || dom: 0.0017 || loss: 6.4374 ||\n",
      "\n",
      "Timer: 0.2064 sec.\n",
      "iter : 5090 || loc: 2.1623 || conf: 4.4334 || dom: 0.0014 || loss: 6.5970 ||\n",
      "\n",
      "Timer: 0.1999 sec.\n",
      "iter : 5100 || loc: 2.0921 || conf: 5.0258 || dom: 0.0016 || loss: 7.1195 ||\n",
      "\n",
      "Timer: 0.2061 sec.\n",
      "iter : 5110 || loc: 2.2815 || conf: 3.8718 || dom: 0.0010 || loss: 6.1543 ||\n",
      "\n",
      "Timer: 0.2022 sec.\n",
      "iter : 5120 || loc: 2.6146 || conf: 4.5460 || dom: 0.0008 || loss: 7.1614 ||\n",
      "\n",
      "Timer: 0.2031 sec.\n",
      "iter : 5130 || loc: 2.3049 || conf: 4.1193 || dom: 0.0007 || loss: 6.4250 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 5140 || loc: 1.8363 || conf: 4.5351 || dom: 0.0022 || loss: 6.3736 ||\n",
      "\n",
      "Timer: 0.2005 sec.\n",
      "iter : 5150 || loc: 2.1218 || conf: 4.5266 || dom: 0.0014 || loss: 6.6497 ||\n",
      "\n",
      "Timer: 0.2037 sec.\n",
      "iter : 5160 || loc: 2.2569 || conf: 4.3033 || dom: 0.0012 || loss: 6.5614 ||\n",
      "\n",
      "Timer: 0.2027 sec.\n",
      "iter : 5170 || loc: 1.9690 || conf: 5.1737 || dom: 0.0015 || loss: 7.1442 ||\n",
      "\n",
      "Timer: 0.2066 sec.\n",
      "iter : 5180 || loc: 2.1705 || conf: 4.6231 || dom: 0.0011 || loss: 6.7947 ||\n",
      "\n",
      "Timer: 0.2021 sec.\n",
      "iter : 5190 || loc: 2.1049 || conf: 4.7712 || dom: 0.0014 || loss: 6.8775 ||\n",
      "\n",
      "Timer: 0.1991 sec.\n",
      "iter : 5200 || loc: 2.1296 || conf: 4.5033 || dom: 0.0013 || loss: 6.6342 ||\n",
      "\n",
      "Timer: 0.2137 sec.\n",
      "iter : 5210 || loc: 1.8805 || conf: 4.1158 || dom: 0.0013 || loss: 5.9975 ||\n",
      "\n",
      "Timer: 0.2093 sec.\n",
      "iter : 5220 || loc: 2.1377 || conf: 4.3538 || dom: 0.0013 || loss: 6.4927 ||\n",
      "\n",
      "Timer: 0.1994 sec.\n",
      "iter : 5230 || loc: 1.9065 || conf: 4.5511 || dom: 0.0019 || loss: 6.4595 ||\n",
      "\n",
      "Timer: 0.2010 sec.\n",
      "iter : 5240 || loc: 2.1808 || conf: 4.7296 || dom: 0.0021 || loss: 6.9124 ||\n",
      "\n",
      "Timer: 0.2054 sec.\n",
      "iter : 5250 || loc: 1.9752 || conf: 4.6745 || dom: 0.0014 || loss: 6.6512 ||\n",
      "\n",
      "Timer: 0.2062 sec.\n",
      "iter : 5260 || loc: 2.3265 || conf: 4.3490 || dom: 0.0014 || loss: 6.6769 ||\n",
      "\n",
      "Timer: 0.2050 sec.\n",
      "iter : 5270 || loc: 2.5596 || conf: 5.3288 || dom: 0.0010 || loss: 7.8893 ||\n",
      "\n",
      "Timer: 0.2027 sec.\n",
      "iter : 5280 || loc: 1.8738 || conf: 3.5980 || dom: 0.0014 || loss: 5.4732 ||\n",
      "\n",
      "Timer: 0.2120 sec.\n",
      "iter : 5290 || loc: 1.9864 || conf: 4.6693 || dom: 0.0016 || loss: 6.6572 ||\n",
      "\n",
      "Timer: 0.2045 sec.\n",
      "iter : 5300 || loc: 1.7060 || conf: 3.9411 || dom: 0.0014 || loss: 5.6485 ||\n",
      "\n",
      "Timer: 0.2048 sec.\n",
      "iter : 5310 || loc: 2.1633 || conf: 4.3326 || dom: 0.0007 || loss: 6.4967 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 5320 || loc: 2.3236 || conf: 4.6326 || dom: 0.0010 || loss: 6.9572 ||\n",
      "\n",
      "Timer: 0.2009 sec.\n",
      "iter : 5330 || loc: 2.3433 || conf: 4.0419 || dom: 0.0011 || loss: 6.3862 ||\n",
      "\n",
      "Timer: 0.2093 sec.\n",
      "iter : 5340 || loc: 2.2641 || conf: 4.1232 || dom: 0.0012 || loss: 6.3884 ||\n",
      "\n",
      "Timer: 0.2053 sec.\n",
      "iter : 5350 || loc: 1.9712 || conf: 3.8713 || dom: 0.0013 || loss: 5.8438 ||\n",
      "\n",
      "Timer: 0.1994 sec.\n",
      "iter : 5360 || loc: 2.1525 || conf: 4.1967 || dom: 0.0014 || loss: 6.3505 ||\n",
      "\n",
      "Timer: 0.2051 sec.\n",
      "iter : 5370 || loc: 1.9463 || conf: 4.9735 || dom: 0.0012 || loss: 6.9209 ||\n",
      "\n",
      "Timer: 0.2000 sec.\n",
      "iter : 5380 || loc: 1.8948 || conf: 4.1994 || dom: 0.0011 || loss: 6.0953 ||\n",
      "\n",
      "Timer: 0.2083 sec.\n",
      "iter : 5390 || loc: 2.3038 || conf: 4.8367 || dom: 0.0011 || loss: 7.1416 ||\n",
      "\n",
      "Timer: 0.2092 sec.\n",
      "iter : 5400 || loc: inf || conf: 4.7149 || dom: 0.0011 || loss: inf ||\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.2096 sec.\n",
      "iter : 5410 || loc: 1.7190 || conf: 4.0404 || dom: 0.0013 || loss: 5.7607 ||\n",
      "\n",
      "Timer: 0.2041 sec.\n",
      "iter : 5420 || loc: 1.8649 || conf: 4.4223 || dom: 0.0011 || loss: 6.2883 ||\n",
      "\n",
      "Timer: 0.2062 sec.\n",
      "iter : 5430 || loc: 2.1562 || conf: 3.8554 || dom: 0.0011 || loss: 6.0126 ||\n",
      "\n",
      "Timer: 0.2074 sec.\n",
      "iter : 5440 || loc: 2.3819 || conf: 4.4260 || dom: 0.0007 || loss: 6.8085 ||\n",
      "\n",
      "Timer: 0.2001 sec.\n",
      "iter : 5450 || loc: 1.7881 || conf: 4.7805 || dom: 0.0013 || loss: 6.5699 ||\n",
      "\n",
      "Timer: 0.2098 sec.\n",
      "iter : 5460 || loc: 2.0277 || conf: 4.1087 || dom: 0.0009 || loss: 6.1373 ||\n",
      "\n",
      "Timer: 0.2046 sec.\n",
      "iter : 5470 || loc: 2.9855 || conf: 5.2952 || dom: 0.0015 || loss: 8.2822 ||\n",
      "\n",
      "Timer: 0.2032 sec.\n",
      "iter : 5480 || loc: 2.0946 || conf: 5.1079 || dom: 0.0007 || loss: 7.2032 ||\n",
      "\n",
      "Timer: 0.2091 sec.\n",
      "iter : 5490 || loc: 2.1404 || conf: 4.8402 || dom: 0.0011 || loss: 6.9817 ||\n",
      "\n",
      "Timer: 0.2078 sec.\n",
      "iter : 5500 || loc: 2.2454 || conf: 4.5870 || dom: 0.0016 || loss: 6.8339 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 5510 || loc: 2.5017 || conf: 3.6487 || dom: 0.0021 || loss: 6.1525 ||\n",
      "\n",
      "Timer: 0.2060 sec.\n",
      "iter : 5520 || loc: 1.7527 || conf: 5.1396 || dom: 0.0018 || loss: 6.8941 ||\n",
      "\n",
      "Timer: 0.2093 sec.\n",
      "iter : 5530 || loc: 2.3022 || conf: 4.4810 || dom: 0.0013 || loss: 6.7845 ||\n",
      "\n",
      "Timer: 0.2128 sec.\n",
      "iter : 5540 || loc: 2.4430 || conf: 4.5962 || dom: 0.0017 || loss: 7.0410 ||\n",
      "\n",
      "Timer: 0.2030 sec.\n",
      "iter : 5550 || loc: 2.1216 || conf: 4.1785 || dom: 0.0013 || loss: 6.3014 ||\n",
      "\n",
      "Timer: 0.2052 sec.\n",
      "iter : 5560 || loc: 1.9807 || conf: 4.0794 || dom: 0.0010 || loss: 6.0611 ||\n",
      "\n",
      "Timer: 0.2030 sec.\n",
      "iter : 5570 || loc: 2.3085 || conf: 4.4977 || dom: 0.0010 || loss: 6.8072 ||\n",
      "\n",
      "Timer: 0.1995 sec.\n",
      "iter : 5580 || loc: 2.1707 || conf: 4.0761 || dom: 0.0016 || loss: 6.2484 ||\n",
      "\n",
      "Timer: 0.2033 sec.\n",
      "iter : 5590 || loc: 2.6583 || conf: 4.3197 || dom: 0.0015 || loss: 6.9796 ||\n",
      "\n",
      "Timer: 0.2047 sec.\n",
      "iter : 5600 || loc: 2.0061 || conf: 3.7168 || dom: 0.0008 || loss: 5.7237 ||\n",
      "\n",
      "Timer: 0.2081 sec.\n",
      "iter : 5610 || loc: 1.8362 || conf: 4.1496 || dom: 0.0009 || loss: 5.9867 ||\n",
      "\n",
      "Timer: 0.2055 sec.\n",
      "iter : 5620 || loc: 2.2507 || conf: 4.1393 || dom: 0.0006 || loss: 6.3906 ||\n",
      "\n",
      "Timer: 0.2028 sec.\n",
      "iter : 5630 || loc: 2.1744 || conf: 4.2742 || dom: 0.0009 || loss: 6.4496 ||\n",
      "\n",
      "Timer: 0.2062 sec.\n",
      "iter : 5640 || loc: 1.9682 || conf: 4.9272 || dom: 0.0011 || loss: 6.8965 ||\n",
      "\n",
      "Timer: 0.2052 sec.\n",
      "iter : 5650 || loc: 2.1435 || conf: 4.8037 || dom: 0.0011 || loss: 6.9483 ||\n",
      "\n",
      "Timer: 0.2001 sec.\n",
      "iter : 5660 || loc: 1.9315 || conf: 4.3819 || dom: 0.0013 || loss: 6.3147 ||\n",
      "\n",
      "Timer: 0.2032 sec.\n",
      "iter : 5670 || loc: 1.9001 || conf: 3.9851 || dom: 0.0015 || loss: 5.8866 ||\n",
      "\n",
      "Timer: 0.1999 sec.\n",
      "iter : 5680 || loc: 1.9493 || conf: 4.7041 || dom: 0.0012 || loss: 6.6546 ||\n",
      "\n",
      "Timer: 0.2069 sec.\n",
      "iter : 5690 || loc: 2.1505 || conf: 4.0597 || dom: 0.0016 || loss: 6.2118 ||\n",
      "\n",
      "Timer: 0.2135 sec.\n",
      "iter : 5700 || loc: 1.9623 || conf: 3.9888 || dom: 0.0012 || loss: 5.9523 ||\n",
      "\n",
      "Timer: 0.2058 sec.\n",
      "iter : 5710 || loc: 2.5110 || conf: 3.5125 || dom: 0.0015 || loss: 6.0249 ||\n",
      "\n",
      "Timer: 0.2011 sec.\n",
      "iter : 5720 || loc: 2.2075 || conf: 4.4544 || dom: 0.0016 || loss: 6.6635 ||\n",
      "\n",
      "Timer: 0.2155 sec.\n",
      "iter : 5730 || loc: 1.8020 || conf: 3.8006 || dom: 0.0016 || loss: 5.6041 ||\n",
      "\n",
      "Timer: 0.2128 sec.\n",
      "iter : 5740 || loc: 2.5256 || conf: 5.0223 || dom: 0.0017 || loss: 7.5495 ||\n",
      "\n",
      "Timer: 0.2048 sec.\n",
      "iter : 5750 || loc: 2.0754 || conf: 4.0565 || dom: 0.0018 || loss: 6.1338 ||\n",
      "\n",
      "Timer: 0.2003 sec.\n",
      "iter : 5760 || loc: 2.3336 || conf: 4.1419 || dom: 0.0010 || loss: 6.4765 ||\n",
      "\n",
      "Timer: 0.1975 sec.\n",
      "iter : 5770 || loc: 2.2424 || conf: 4.7376 || dom: 0.0014 || loss: 6.9814 ||\n",
      "\n",
      "Timer: 0.2012 sec.\n",
      "iter : 5780 || loc: 2.1986 || conf: 4.4412 || dom: 0.0019 || loss: 6.6418 ||\n",
      "\n",
      "Timer: 0.2145 sec.\n",
      "iter : 5790 || loc: 2.4519 || conf: 4.5936 || dom: 0.0010 || loss: 7.0465 ||\n",
      "\n",
      "Timer: 0.2086 sec.\n",
      "iter : 5800 || loc: 2.1291 || conf: 3.9599 || dom: 0.0014 || loss: 6.0905 ||\n",
      "\n",
      "Timer: 0.2113 sec.\n",
      "iter : 5810 || loc: 2.0656 || conf: 4.4351 || dom: 0.0011 || loss: 6.5017 ||\n",
      "\n",
      "Timer: 0.1977 sec.\n",
      "iter : 5820 || loc: 2.4018 || conf: 3.7303 || dom: 0.0007 || loss: 6.1328 ||\n",
      "\n",
      "Timer: 0.2140 sec.\n",
      "iter : 5830 || loc: 2.6127 || conf: 3.8038 || dom: 0.0009 || loss: 6.4173 ||\n",
      "\n",
      "Timer: 0.2006 sec.\n",
      "iter : 5840 || loc: 2.2337 || conf: 4.7494 || dom: 0.0015 || loss: 6.9847 ||\n",
      "\n",
      "Timer: 0.2025 sec.\n",
      "iter : 5850 || loc: 2.0167 || conf: 5.5690 || dom: 0.0009 || loss: 7.5866 ||\n",
      "\n",
      "Timer: 0.2079 sec.\n",
      "iter : 5860 || loc: 2.5554 || conf: 4.8591 || dom: 0.0010 || loss: 7.4156 ||\n",
      "\n",
      "Timer: 0.2032 sec.\n",
      "iter : 5870 || loc: 1.9521 || conf: 4.4763 || dom: 0.0014 || loss: 6.4299 ||\n",
      "\n",
      "Timer: 0.1967 sec.\n",
      "iter : 5880 || loc: 2.0675 || conf: 4.7957 || dom: 0.0010 || loss: 6.8643 ||\n",
      "\n",
      "Timer: 0.2001 sec.\n",
      "iter : 5890 || loc: 2.2671 || conf: 5.2696 || dom: 0.0013 || loss: 7.5380 ||\n",
      "\n",
      "Timer: 0.2220 sec.\n",
      "iter : 5900 || loc: 1.7039 || conf: 4.0520 || dom: 0.0014 || loss: 5.7573 ||\n",
      "\n",
      "Timer: 0.2081 sec.\n",
      "iter : 5910 || loc: 1.9460 || conf: 4.0785 || dom: 0.0012 || loss: 6.0257 ||\n",
      "\n",
      "Timer: 0.2041 sec.\n",
      "iter : 5920 || loc: 2.3191 || conf: 4.5889 || dom: 0.0014 || loss: 6.9094 ||\n",
      "\n",
      "Timer: 0.1993 sec.\n",
      "iter : 5930 || loc: 2.1959 || conf: 3.9991 || dom: 0.0007 || loss: 6.1957 ||\n",
      "\n",
      "Timer: 0.2124 sec.\n",
      "iter : 5940 || loc: 2.1258 || conf: 3.6866 || dom: 0.0007 || loss: 5.8132 ||\n",
      "\n",
      "Timer: 0.2045 sec.\n",
      "iter : 5950 || loc: 2.4649 || conf: 4.6768 || dom: 0.0008 || loss: 7.1425 ||\n",
      "\n",
      "Timer: 0.2023 sec.\n",
      "iter : 5960 || loc: 1.7896 || conf: 4.1807 || dom: 0.0017 || loss: 5.9720 ||\n",
      "\n",
      "Timer: 0.2173 sec.\n",
      "iter : 5970 || loc: 2.0962 || conf: 4.0280 || dom: 0.0015 || loss: 6.1257 ||\n",
      "\n",
      "Timer: 0.2044 sec.\n",
      "iter : 5980 || loc: 2.2429 || conf: 4.4882 || dom: 0.0007 || loss: 6.7318 ||\n",
      "\n",
      "Timer: 0.2078 sec.\n",
      "iter : 5990 || loc: 2.0026 || conf: 4.1070 || dom: 0.0011 || loss: 6.1108 ||\n",
      "\n",
      "Timer: 0.2102 sec.\n",
      "iter : 6000 || loc: 2.2415 || conf: 4.0772 || dom: 0.0010 || loss: 6.3197 ||\n",
      "\n",
      "Saving state, iter: 6000\n",
      "Timer: 0.2091 sec.\n",
      "iter : 6010 || loc: 2.2580 || conf: 4.0425 || dom: 0.0011 || loss: 6.3015 ||\n",
      "\n",
      "Timer: 0.2032 sec.\n",
      "iter : 6020 || loc: 1.7549 || conf: 5.2045 || dom: 0.0014 || loss: 6.9609 ||\n",
      "\n",
      "Timer: 0.2051 sec.\n",
      "iter : 6030 || loc: 2.4547 || conf: 4.2358 || dom: 0.0011 || loss: 6.6916 ||\n",
      "\n",
      "Timer: 0.2005 sec.\n",
      "iter : 6040 || loc: 1.9495 || conf: 3.8352 || dom: 0.0008 || loss: 5.7855 ||\n",
      "\n",
      "Timer: 0.1990 sec.\n",
      "iter : 6050 || loc: 2.2474 || conf: 4.4440 || dom: 0.0013 || loss: 6.6927 ||\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "KeyboardInterrupt\n",
      "Process Process-5:\n",
      "Process Process-6:\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 341, in get\n",
      "    with self._rlock:\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 40, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/new_data/gpu/utkrsh/DomainAdaptation/commonData.py\", line 37, in __getitem__\n",
      "    img, targets = self.cocoData[indx]\n",
      "  File \"/new_data/gpu/utkrsh/DomainAdaptation/data/coco2014.py\", line 89, in __getitem__\n",
      "    im, gt, _, _ = self.pull_item(index)\n",
      "  File \"/new_data/gpu/utkrsh/DomainAdaptation/data/coco2014.py\", line 99, in pull_item\n",
      "    img = cv2.imread(self.image_root+imgObj['file_name']) #numpy array\n",
      "KeyboardInterrupt\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _pin_memory_loop\n",
      "    r = in_queue.get()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/queues.py\", line 344, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/reduction.py\", line 182, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "  File \"/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/multiprocessing/reduction.py\", line 153, in recvfds\n",
      "    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_LEN(bytes_size))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-445e1d55033c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-445e1d55033c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m#CHANGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mloss_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_l\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_c\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/new_data/gpu/utkrsh/DomainAdaptation/layers/modules/multibox_loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, predictions, targets)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mdefaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             match(self.threshold, truths, defaults, self.variance, labels,\n\u001b[0;32m---> 80\u001b[0;31m                   loc_t, conf_t, idx)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mloc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloc_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/new_data/gpu/utkrsh/DomainAdaptation/layers/box_utils.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(threshold, truths, priors, variances, labels, loc_t, conf_t, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# ensure every gt matches with its prior of max overlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_prior_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mbest_truth_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_prior_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_truth_idx\u001b[0m\u001b[0;34m]\u001b[0m          \u001b[0;31m# Shape: [num_priors,4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_truth_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m         \u001b[0;31m# Shape: [num_priors]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    # loss counters\n",
    "    loc_loss = 0  # epoch\n",
    "    conf_loss = 0\n",
    "    epoch = 0\n",
    "    print('Loading Dataset...')\n",
    "\n",
    "#CHANGE\n",
    "    dataset = commonDataset(voc_root, train_sets, ssd_dim, means,\n",
    "                cocoimg, annFile)\n",
    "    #dataset = VOCDetection(voc_root, train_sets, SSDAugmentation(\n",
    "    #    ssd_dim, means), AnnotationTransform())\n",
    "\n",
    "    epoch_size = len(dataset) // batch_size\n",
    "    print('Training SSD on', dataset.name)\n",
    "    step_index = 0\n",
    "    if visdom:\n",
    "        # initialize visdom loss plot\n",
    "        lot = viz.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1, 3)).cpu(),\n",
    "            opts=dict(\n",
    "                xlabel='Iteration',\n",
    "                ylabel='Loss',\n",
    "                title='Current SSD Training Loss',\n",
    "                legend=['Loc Loss', 'Conf Loss', 'Loss']\n",
    "            )\n",
    "        )\n",
    "        epoch_lot = viz.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1, 3)).cpu(),\n",
    "            opts=dict(\n",
    "                xlabel='Epoch',\n",
    "                ylabel='Loss',\n",
    "                title='Epoch SSD Training Loss',\n",
    "                legend=['Loc Loss', 'Conf Loss', 'Loss']\n",
    "            )\n",
    "        )\n",
    "    batch_iterator = None\n",
    "    data_loader = data.DataLoader(dataset, batch_size, num_workers=num_workers,\n",
    "                                  shuffle=True, collate_fn=detection_collate, pin_memory=True)\n",
    "    for iteration in range(start_iter, max_iter):\n",
    "        if (not batch_iterator) or (iteration % epoch_size == 0):\n",
    "            # create batch iterator\n",
    "            batch_iterator = iter(data_loader)\n",
    "        if iteration in stepvalues:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, gamma, step_index)\n",
    "            if visdom:\n",
    "                viz.line(\n",
    "                    X=torch.ones((1, 3)).cpu() * epoch,\n",
    "                    Y=torch.Tensor([loc_loss, conf_loss,\n",
    "                        loc_loss + conf_loss]).unsqueeze(0).cpu() / epoch_size,\n",
    "                    win=epoch_lot,\n",
    "                    update='append'\n",
    "                )\n",
    "            # reset epoch loss counters\n",
    "            loc_loss = 0\n",
    "            conf_loss = 0\n",
    "            epoch += 1\n",
    "\n",
    "        # load train data\n",
    "        images, targets = next(batch_iterator)\n",
    "\n",
    "        if cuda:\n",
    "            images = Variable(images.cuda())\n",
    "            targets = [Variable(anno.cuda(), volatile=True) for anno in targets]\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            targets = [Variable(anno, volatile=True) for anno in targets]\n",
    "        # forward\n",
    "        t0 = time.time()\n",
    "        out = net(images)\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "#CHANGE\n",
    "        loss_l, loss_c, loss_d = criterion(out, targets)\n",
    "        loss = loss_l + loss_c + loss_d\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        loc_loss += loss_l.data[0]\n",
    "        conf_loss += loss_c.data[0]\n",
    "        if iteration % 10 == 0:\n",
    "            print('Timer: %.4f sec.' % (t1 - t0))\n",
    "            print(\"iter : \"+repr(iteration)+\" || loc: %.4f || conf: %.4f || dom: %.4f || loss: %.4f ||\\n\" %\n",
    "                       (loss_l.data[0], loss_c.data[0], loss_d.data[0], loss.data[0]) )\n",
    "            if visdom and send_images_to_visdom:\n",
    "                random_batch_index = np.random.randint(images.size(0))\n",
    "                viz.image(images.data[random_batch_index].cpu().numpy())\n",
    "        if visdom:\n",
    "            viz.line(\n",
    "                X=torch.ones((1, 3)).cpu() * iteration,\n",
    "                Y=torch.Tensor([loss_l.data[0], loss_c.data[0],\n",
    "                    loss_l.data[0] + loss_c.data[0]]).unsqueeze(0).cpu(),\n",
    "                win=lot,\n",
    "                update='append'\n",
    "            )\n",
    "            # hacky fencepost solution for 0th epoch plot\n",
    "            if iteration == 0:\n",
    "                viz.line(\n",
    "                    X=torch.zeros((1, 3)).cpu(),\n",
    "                    Y=torch.Tensor([loc_loss, conf_loss,\n",
    "                        loc_loss + conf_loss]).unsqueeze(0).cpu(),\n",
    "                    win=epoch_lot,\n",
    "                    update=True\n",
    "                )\n",
    "        if iteration % 2000 == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(ssd_net.state_dict(), 'weights/ssd300_0712_COCO14_' +\n",
    "                       repr(iteration) + '.pth')\n",
    "    torch.save(ssd_net.state_dict(), save_folder + '' + version + '.pth')\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
