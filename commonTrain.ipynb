{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T11:48:24.960510Z",
     "start_time": "2018-02-04T11:48:21.325223Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "#CHANGE\n",
    "from data import v2, v1, AnnotationTransform, VOCDetection, detection_collate, VOC_CLASSES\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import numpy as np\n",
    "import time\n",
    "from commonData import commonDataset\n",
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T11:48:24.973424Z",
     "start_time": "2018-02-04T11:48:24.962790Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "#CHANGE\n",
    "cocoimgPath = \"/new_data/gpu/utkrsh/coco/images/train2014/\"\n",
    "annFilePath = \"/new_data/gpu/utkrsh/coco/annotations/instances_train2014.json\"\n",
    "# RESUME = \"./weights/ssd300_0712_COCO14_2000_run2_BCELoss.pth\" # change to saved model file path\n",
    "RESUME = None\n",
    "START_ITER = 1\n",
    "CUDA = True\n",
    "VOCroot = \"/users/gpu/utkrsh/data/VOCdevkit/\"\n",
    "logFolder = \"./.logs/run1_singleGPU_BCELoss/\"\n",
    "logger = Logger(logFolder)\n",
    "logTensorboard = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T11:48:25.261511Z",
     "start_time": "2018-02-04T11:48:24.974966Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version ='v2'\n",
    "basenet ='vgg16_reducedfc.pth'\n",
    "jaccard_threshold = 0.5\n",
    "batch_size = 16\n",
    "resume = RESUME\n",
    "num_workers = 4\n",
    "iterations = 120000\n",
    "start_iter = START_ITER\n",
    "cuda = CUDA\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "gamma = 0.1\n",
    "log_iters = False\n",
    "visdom = False\n",
    "send_images_to_visdom = False\n",
    "save_folder = 'weights/'\n",
    "cocoimg = cocoimgPath\n",
    "annFile = annFilePath\n",
    "voc_root = VOCroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-04T11:48:21.321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base network...\n",
      "Initializing weights...\n"
     ]
    }
   ],
   "source": [
    "if cuda and torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "cfg = (v1, v2)[version == 'v2']\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "train_sets = [('2007', 'trainval')]\n",
    "# train_sets = 'train'\n",
    "ssd_dim = 300  # only support 300 now\n",
    "means = (104, 117, 123)  # only support voc now\n",
    "num_classes = len(VOC_CLASSES) + 1\n",
    "batch_size = batch_size\n",
    "accum_batch_size = 32\n",
    "iter_size = accum_batch_size / batch_size\n",
    "max_iter = 30000\n",
    "weight_decay = 0.0005\n",
    "stepvalues = (80000, 100000, 120000)\n",
    "gamma = 0.1\n",
    "momentum = 0.9\n",
    "\n",
    "if visdom:\n",
    "    import visdom\n",
    "    viz = visdom.Visdom()\n",
    "\n",
    "ssd_net = build_ssd('train', 300, num_classes)\n",
    "net = ssd_net\n",
    "\n",
    "if False:\n",
    "    net = torch.nn.DataParallel(ssd_net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if resume:\n",
    "    print('Resuming training, loading {}...'.format(resume))\n",
    "    ssd_net.load_weights(resume)\n",
    "else:\n",
    "    vgg_weights = torch.load(save_folder + basenet)\n",
    "    print('Loading base network...')\n",
    "    ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "if cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "if not resume:\n",
    "    print('Initializing weights...')\n",
    "    # initialize newly added layers' weights with xavier method\n",
    "    ssd_net.extras.apply(weights_init)\n",
    "    ssd_net.loc.apply(weights_init)\n",
    "    ssd_net.conf.apply(weights_init)\n",
    "#CHANGE\n",
    "    ssd_net.dmn.apply(weights_init)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = MultiBoxLoss(num_classes, 0.5, True, 0, True, 3, 0.5, False, cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T11:31:50.730741Z",
     "start_time": "2018-02-03T11:31:40.410291Z"
    }
   },
   "source": [
    "dataset = commonDataset(voc_root, train_sets, ssd_dim, means,\n",
    "                cocoimg, annFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T11:31:53.182217Z",
     "start_time": "2018-02-03T11:31:52.979601Z"
    },
    "collapsed": true
   },
   "source": [
    "data_loader = data.DataLoader(dataset, batch_size, num_workers=num_workers,\n",
    "                              shuffle=True, collate_fn=detection_collate, pin_memory=True)\n",
    "batch_iter = iter(data_loader)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img, targets = next(batch_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-04T11:10:02.430510Z",
     "start_time": "2018-02-04T11:10:02.210149Z"
    }
   },
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-04T10:57:11.236Z"
    }
   },
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-02-04T11:48:21.324Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "loading annotations into memory...\n",
      "Done (t=9.65s)\n",
      "creating index...\n",
      "index created!\n",
      "Training SSD on VOC07_and_COCO14_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py:450: UserWarning: mask is not broadcastable to self, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return tensor.masked_fill_(mask, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.2019 sec.\n",
      "iter : 10 || loc: 3.2641 || conf: 14.4058 || dom: 0.0020 || loss: 17.6719 ||\n",
      "\n",
      "Timer: 0.1986 sec.\n",
      "iter : 20 || loc: 3.0107 || conf: 12.8385 || dom: 0.0024 || loss: 15.8516 ||\n",
      "\n",
      "Timer: 0.1993 sec.\n",
      "iter : 30 || loc: 3.1137 || conf: 11.0757 || dom: 0.0032 || loss: 14.1926 ||\n",
      "\n",
      "Timer: 0.1968 sec.\n",
      "iter : 40 || loc: 3.3932 || conf: 9.2630 || dom: 0.0017 || loss: 12.6579 ||\n",
      "\n",
      "Timer: 0.1989 sec.\n",
      "iter : 50 || loc: 2.8676 || conf: 7.7530 || dom: 0.0028 || loss: 10.6233 ||\n",
      "\n",
      "Timer: 0.2013 sec.\n",
      "iter : 60 || loc: 3.1021 || conf: 8.4156 || dom: 0.0023 || loss: 11.5201 ||\n",
      "\n",
      "Timer: 0.1910 sec.\n",
      "iter : 70 || loc: 2.9545 || conf: 7.1044 || dom: 0.0032 || loss: 10.0621 ||\n",
      "\n",
      "Timer: 0.2003 sec.\n",
      "iter : 80 || loc: 2.9028 || conf: 6.3668 || dom: 0.0023 || loss: 9.2719 ||\n",
      "\n",
      "Timer: 0.1960 sec.\n",
      "iter : 90 || loc: 3.2444 || conf: 5.7655 || dom: 0.0027 || loss: 9.0126 ||\n",
      "\n",
      "Timer: 0.2078 sec.\n",
      "iter : 100 || loc: 2.9452 || conf: 5.7137 || dom: 0.0023 || loss: 8.6613 ||\n",
      "\n",
      "Timer: 0.1951 sec.\n",
      "iter : 110 || loc: 3.6500 || conf: 5.3931 || dom: 0.0029 || loss: 9.0460 ||\n",
      "\n",
      "Timer: 0.2139 sec.\n",
      "iter : 120 || loc: 2.7560 || conf: 5.9522 || dom: 0.0023 || loss: 8.7104 ||\n",
      "\n",
      "Timer: 0.2017 sec.\n",
      "iter : 130 || loc: 3.0127 || conf: 5.9184 || dom: 0.0025 || loss: 8.9336 ||\n",
      "\n",
      "Timer: 0.1963 sec.\n",
      "iter : 140 || loc: 2.9962 || conf: 6.3433 || dom: 0.0022 || loss: 9.3416 ||\n",
      "\n",
      "Timer: 0.2058 sec.\n",
      "iter : 150 || loc: 2.9182 || conf: 6.1242 || dom: 0.0030 || loss: 9.0454 ||\n",
      "\n",
      "Timer: 0.2116 sec.\n",
      "iter : 160 || loc: 3.0625 || conf: 5.9853 || dom: 0.0023 || loss: 9.0501 ||\n",
      "\n",
      "Timer: 0.1945 sec.\n",
      "iter : 170 || loc: 2.8131 || conf: 5.5047 || dom: 0.0017 || loss: 8.3195 ||\n",
      "\n",
      "Timer: 0.2091 sec.\n",
      "iter : 180 || loc: 2.6890 || conf: 7.1243 || dom: 0.0024 || loss: 9.8157 ||\n",
      "\n",
      "Timer: 0.2039 sec.\n",
      "iter : 190 || loc: 3.2543 || conf: 9.1605 || dom: 0.0024 || loss: 12.4171 ||\n",
      "\n",
      "Timer: 0.1952 sec.\n",
      "iter : 200 || loc: 2.5380 || conf: 4.9687 || dom: 0.0022 || loss: 7.5088 ||\n",
      "\n",
      "Timer: 0.2057 sec.\n",
      "iter : 210 || loc: 2.4877 || conf: 5.1570 || dom: 0.0028 || loss: 7.6474 ||\n",
      "\n",
      "Timer: 0.2023 sec.\n",
      "iter : 220 || loc: 3.0270 || conf: 5.3868 || dom: 0.0026 || loss: 8.4164 ||\n",
      "\n",
      "Timer: 0.1955 sec.\n",
      "iter : 230 || loc: 2.9840 || conf: 5.2866 || dom: 0.0035 || loss: 8.2741 ||\n",
      "\n",
      "Timer: 0.1955 sec.\n",
      "iter : 240 || loc: 2.9092 || conf: 5.4400 || dom: 0.0023 || loss: 8.3515 ||\n",
      "\n",
      "Timer: 0.1985 sec.\n",
      "iter : 250 || loc: 2.2639 || conf: 4.9736 || dom: 0.0036 || loss: 7.2411 ||\n",
      "\n",
      "Timer: 0.2045 sec.\n",
      "iter : 260 || loc: 2.8546 || conf: 5.1585 || dom: 0.0031 || loss: 8.0162 ||\n",
      "\n",
      "Timer: 0.2013 sec.\n",
      "iter : 270 || loc: 2.8939 || conf: 5.3248 || dom: 0.0022 || loss: 8.2209 ||\n",
      "\n",
      "Timer: 0.1962 sec.\n",
      "iter : 280 || loc: 2.7711 || conf: 4.9972 || dom: 0.0026 || loss: 7.7709 ||\n",
      "\n",
      "Timer: 0.1999 sec.\n",
      "iter : 290 || loc: 2.4290 || conf: 5.1584 || dom: 0.0016 || loss: 7.5889 ||\n",
      "\n",
      "Timer: 0.2004 sec.\n",
      "iter : 300 || loc: 2.9417 || conf: 4.7893 || dom: 0.0029 || loss: 7.7339 ||\n",
      "\n",
      "Timer: 0.1989 sec.\n",
      "iter : 310 || loc: 2.4909 || conf: 4.9561 || dom: 0.0022 || loss: 7.4493 ||\n",
      "\n",
      "Timer: 0.2030 sec.\n",
      "iter : 320 || loc: 2.9426 || conf: 5.9067 || dom: 0.0027 || loss: 8.8520 ||\n",
      "\n",
      "Timer: 0.2093 sec.\n",
      "iter : 330 || loc: 2.9576 || conf: 5.0655 || dom: 0.0018 || loss: 8.0249 ||\n",
      "\n",
      "Timer: 0.2087 sec.\n",
      "iter : 340 || loc: 3.1730 || conf: 5.6540 || dom: 0.0028 || loss: 8.8299 ||\n",
      "\n",
      "Timer: 0.2075 sec.\n",
      "iter : 350 || loc: 2.5341 || conf: 4.1618 || dom: 0.0019 || loss: 6.6977 ||\n",
      "\n",
      "Timer: 0.2042 sec.\n",
      "iter : 360 || loc: 2.7309 || conf: 5.1537 || dom: 0.0019 || loss: 7.8864 ||\n",
      "\n",
      "Timer: 0.1987 sec.\n",
      "iter : 370 || loc: 2.3497 || conf: 5.1170 || dom: 0.0019 || loss: 7.4686 ||\n",
      "\n",
      "Timer: 0.2070 sec.\n",
      "iter : 380 || loc: 3.0315 || conf: 4.7607 || dom: 0.0025 || loss: 7.7947 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 390 || loc: 1.9996 || conf: 4.8004 || dom: 0.0022 || loss: 6.8022 ||\n",
      "\n",
      "Timer: 0.1987 sec.\n",
      "iter : 400 || loc: 2.3884 || conf: 5.7336 || dom: 0.0015 || loss: 8.1235 ||\n",
      "\n",
      "Timer: 0.1973 sec.\n",
      "iter : 410 || loc: 2.1550 || conf: 4.8245 || dom: 0.0024 || loss: 6.9819 ||\n",
      "\n",
      "Timer: 0.2010 sec.\n",
      "iter : 420 || loc: 2.3523 || conf: 5.7236 || dom: 0.0021 || loss: 8.0780 ||\n",
      "\n",
      "Timer: 0.1965 sec.\n",
      "iter : 430 || loc: 2.4730 || conf: 5.1288 || dom: 0.0015 || loss: 7.6034 ||\n",
      "\n",
      "Timer: 0.1957 sec.\n",
      "iter : 440 || loc: 2.3508 || conf: 4.6949 || dom: 0.0030 || loss: 7.0487 ||\n",
      "\n",
      "Timer: 0.2049 sec.\n",
      "iter : 450 || loc: 2.1403 || conf: 4.7751 || dom: 0.0035 || loss: 6.9190 ||\n",
      "\n",
      "Timer: 0.2064 sec.\n",
      "iter : 460 || loc: 2.2576 || conf: 5.3825 || dom: 0.0015 || loss: 7.6416 ||\n",
      "\n",
      "Timer: 0.1973 sec.\n",
      "iter : 470 || loc: 2.8761 || conf: 5.1586 || dom: 0.0026 || loss: 8.0372 ||\n",
      "\n",
      "Timer: 0.2155 sec.\n",
      "iter : 480 || loc: 2.4816 || conf: 5.1044 || dom: 0.0022 || loss: 7.5882 ||\n",
      "\n",
      "Timer: 0.1994 sec.\n",
      "iter : 490 || loc: 2.3045 || conf: 5.3764 || dom: 0.0034 || loss: 7.6844 ||\n",
      "\n",
      "Timer: 0.2017 sec.\n",
      "iter : 500 || loc: 2.5080 || conf: 4.7886 || dom: 0.0017 || loss: 7.2983 ||\n",
      "\n",
      "Timer: 0.1960 sec.\n",
      "iter : 510 || loc: 2.6261 || conf: 4.5069 || dom: 0.0020 || loss: 7.1350 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 520 || loc: 2.5421 || conf: 4.6252 || dom: 0.0017 || loss: 7.1690 ||\n",
      "\n",
      "Timer: 0.2011 sec.\n",
      "iter : 530 || loc: 2.5845 || conf: 4.6356 || dom: 0.0023 || loss: 7.2224 ||\n",
      "\n",
      "Timer: 0.2158 sec.\n",
      "iter : 540 || loc: 2.2676 || conf: 4.9275 || dom: 0.0023 || loss: 7.1973 ||\n",
      "\n",
      "Timer: 0.2009 sec.\n",
      "iter : 550 || loc: 2.5504 || conf: 4.6739 || dom: 0.0033 || loss: 7.2276 ||\n",
      "\n",
      "Timer: 0.2042 sec.\n",
      "iter : 560 || loc: 2.2732 || conf: 5.2393 || dom: 0.0025 || loss: 7.5151 ||\n",
      "\n",
      "Timer: 0.2036 sec.\n",
      "iter : 570 || loc: 2.4376 || conf: 5.0709 || dom: 0.0019 || loss: 7.5105 ||\n",
      "\n",
      "Timer: 0.2018 sec.\n",
      "iter : 580 || loc: 2.4474 || conf: 4.9908 || dom: 0.0026 || loss: 7.4407 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 590 || loc: 1.9359 || conf: 4.4275 || dom: 0.0022 || loss: 6.3656 ||\n",
      "\n",
      "Timer: 0.2064 sec.\n",
      "iter : 600 || loc: 2.0478 || conf: 4.7296 || dom: 0.0026 || loss: 6.7800 ||\n",
      "\n",
      "Timer: 0.1988 sec.\n",
      "iter : 610 || loc: 2.4303 || conf: 4.7787 || dom: 0.0026 || loss: 7.2116 ||\n",
      "\n",
      "Timer: 0.2057 sec.\n",
      "iter : 620 || loc: 2.4791 || conf: 5.7452 || dom: 0.0019 || loss: 8.2262 ||\n",
      "\n",
      "Timer: 0.2242 sec.\n",
      "iter : 630 || loc: 2.6844 || conf: 4.5958 || dom: 0.0026 || loss: 7.2829 ||\n",
      "\n",
      "Timer: 0.1969 sec.\n",
      "iter : 640 || loc: 2.4883 || conf: 5.9824 || dom: 0.0017 || loss: 8.4724 ||\n",
      "\n",
      "Timer: 0.2023 sec.\n",
      "iter : 650 || loc: 2.0272 || conf: 4.6240 || dom: 0.0019 || loss: 6.6531 ||\n",
      "\n",
      "Timer: 0.2033 sec.\n",
      "iter : 660 || loc: 2.9259 || conf: 4.3060 || dom: 0.0021 || loss: 7.2341 ||\n",
      "\n",
      "Timer: 0.2048 sec.\n",
      "iter : 670 || loc: 2.0223 || conf: 4.3802 || dom: 0.0024 || loss: 6.4049 ||\n",
      "\n",
      "Timer: 0.1937 sec.\n",
      "iter : 680 || loc: 2.1802 || conf: 5.6856 || dom: 0.0015 || loss: 7.8673 ||\n",
      "\n",
      "Timer: 0.2027 sec.\n",
      "iter : 690 || loc: 3.0060 || conf: 4.5947 || dom: 0.0018 || loss: 7.6025 ||\n",
      "\n",
      "Timer: 0.1956 sec.\n",
      "iter : 700 || loc: 2.4338 || conf: 4.7854 || dom: 0.0018 || loss: 7.2209 ||\n",
      "\n",
      "Timer: 0.2054 sec.\n",
      "iter : 710 || loc: 2.0606 || conf: 4.5222 || dom: 0.0019 || loss: 6.5847 ||\n",
      "\n",
      "Timer: 0.2012 sec.\n",
      "iter : 720 || loc: 2.0480 || conf: 5.0837 || dom: 0.0031 || loss: 7.1348 ||\n",
      "\n",
      "Timer: 0.2067 sec.\n",
      "iter : 730 || loc: 2.4875 || conf: 4.7332 || dom: 0.0033 || loss: 7.2239 ||\n",
      "\n",
      "Timer: 0.1963 sec.\n",
      "iter : 740 || loc: 2.2915 || conf: 5.1022 || dom: 0.0025 || loss: 7.3962 ||\n",
      "\n",
      "Timer: 0.2037 sec.\n",
      "iter : 750 || loc: 2.1796 || conf: 4.8453 || dom: 0.0025 || loss: 7.0274 ||\n",
      "\n",
      "Timer: 0.2198 sec.\n",
      "iter : 760 || loc: 1.9665 || conf: 4.3193 || dom: 0.0027 || loss: 6.2884 ||\n",
      "\n",
      "Timer: 0.2100 sec.\n",
      "iter : 770 || loc: 3.3000 || conf: 4.9958 || dom: 0.0015 || loss: 8.2973 ||\n",
      "\n",
      "Timer: 0.2013 sec.\n",
      "iter : 780 || loc: 1.8421 || conf: 4.7474 || dom: 0.0031 || loss: 6.5926 ||\n",
      "\n",
      "Timer: 0.2028 sec.\n",
      "iter : 790 || loc: 2.0263 || conf: 4.8143 || dom: 0.0017 || loss: 6.8424 ||\n",
      "\n",
      "Timer: 0.2053 sec.\n",
      "iter : 800 || loc: 1.9011 || conf: 4.5888 || dom: 0.0018 || loss: 6.4917 ||\n",
      "\n",
      "Timer: 0.2046 sec.\n",
      "iter : 810 || loc: 2.1722 || conf: 4.5287 || dom: 0.0018 || loss: 6.7027 ||\n",
      "\n",
      "Timer: 0.2523 sec.\n",
      "iter : 820 || loc: 2.3479 || conf: 4.6269 || dom: 0.0025 || loss: 6.9773 ||\n",
      "\n",
      "Timer: 0.2031 sec.\n",
      "iter : 830 || loc: 2.2181 || conf: 4.9595 || dom: 0.0029 || loss: 7.1805 ||\n",
      "\n",
      "Timer: 0.2094 sec.\n",
      "iter : 840 || loc: 2.1414 || conf: 4.4327 || dom: 0.0011 || loss: 6.5752 ||\n",
      "\n",
      "Timer: 0.2017 sec.\n",
      "iter : 850 || loc: 2.0388 || conf: 4.5718 || dom: 0.0027 || loss: 6.6133 ||\n",
      "\n",
      "Timer: 0.2077 sec.\n",
      "iter : 860 || loc: 1.9583 || conf: 5.0591 || dom: 0.0032 || loss: 7.0206 ||\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.2033 sec.\n",
      "iter : 870 || loc: 2.0996 || conf: 5.0295 || dom: 0.0017 || loss: 7.1308 ||\n",
      "\n",
      "Timer: 0.2040 sec.\n",
      "iter : 880 || loc: 2.2734 || conf: 4.4064 || dom: 0.0024 || loss: 6.6822 ||\n",
      "\n",
      "Timer: 0.2080 sec.\n",
      "iter : 890 || loc: 2.4595 || conf: 4.7166 || dom: 0.0016 || loss: 7.1777 ||\n",
      "\n",
      "Timer: 0.2191 sec.\n",
      "iter : 900 || loc: 2.5670 || conf: 4.7494 || dom: 0.0025 || loss: 7.3189 ||\n",
      "\n",
      "Timer: 0.2047 sec.\n",
      "iter : 910 || loc: 2.0092 || conf: 4.7841 || dom: 0.0018 || loss: 6.7951 ||\n",
      "\n",
      "Timer: 0.2116 sec.\n",
      "iter : 920 || loc: 1.9685 || conf: 4.0702 || dom: 0.0018 || loss: 6.0405 ||\n",
      "\n",
      "Timer: 0.1994 sec.\n",
      "iter : 930 || loc: 1.8564 || conf: 4.9184 || dom: 0.0031 || loss: 6.7779 ||\n",
      "\n",
      "Timer: 0.2035 sec.\n",
      "iter : 940 || loc: 1.9761 || conf: 5.0237 || dom: 0.0018 || loss: 7.0016 ||\n",
      "\n",
      "Timer: 0.2057 sec.\n",
      "iter : 950 || loc: 2.2445 || conf: 4.2190 || dom: 0.0034 || loss: 6.4669 ||\n",
      "\n",
      "Timer: 0.2565 sec.\n",
      "iter : 960 || loc: 2.3403 || conf: 4.6682 || dom: 0.0019 || loss: 7.0104 ||\n",
      "\n",
      "Timer: 0.2084 sec.\n",
      "iter : 970 || loc: 2.4893 || conf: 4.6646 || dom: 0.0021 || loss: 7.1560 ||\n",
      "\n",
      "Timer: 0.2014 sec.\n",
      "iter : 980 || loc: 2.6684 || conf: 4.2894 || dom: 0.0018 || loss: 6.9596 ||\n",
      "\n",
      "Timer: 0.2029 sec.\n",
      "iter : 990 || loc: 2.1131 || conf: 3.7982 || dom: 0.0023 || loss: 5.9135 ||\n",
      "\n",
      "Timer: 0.2048 sec.\n",
      "iter : 1000 || loc: 1.9412 || conf: 5.1168 || dom: 0.0025 || loss: 7.0605 ||\n",
      "\n",
      "Timer: 0.2016 sec.\n",
      "iter : 1010 || loc: 1.7683 || conf: 4.5197 || dom: 0.0032 || loss: 6.2912 ||\n",
      "\n",
      "Timer: 0.2043 sec.\n",
      "iter : 1020 || loc: 2.3862 || conf: 4.8106 || dom: 0.0025 || loss: 7.1992 ||\n",
      "\n",
      "Timer: 0.2033 sec.\n",
      "iter : 1030 || loc: 2.2980 || conf: 5.1301 || dom: 0.0026 || loss: 7.4308 ||\n",
      "\n",
      "Timer: 0.1998 sec.\n",
      "iter : 1040 || loc: 2.1851 || conf: 5.1583 || dom: 0.0033 || loss: 7.3467 ||\n",
      "\n",
      "Timer: 0.2071 sec.\n",
      "iter : 1050 || loc: 2.3802 || conf: 5.5738 || dom: 0.0015 || loss: 7.9556 ||\n",
      "\n",
      "Timer: 0.2102 sec.\n",
      "iter : 1060 || loc: 2.0125 || conf: 4.8550 || dom: 0.0017 || loss: 6.8692 ||\n",
      "\n",
      "Timer: 0.2021 sec.\n",
      "iter : 1070 || loc: 2.0044 || conf: 4.5127 || dom: 0.0018 || loss: 6.5189 ||\n",
      "\n",
      "Timer: 0.2067 sec.\n",
      "iter : 1080 || loc: 2.2253 || conf: 4.0725 || dom: 0.0014 || loss: 6.2992 ||\n",
      "\n",
      "Timer: 0.2085 sec.\n",
      "iter : 1090 || loc: 2.1079 || conf: 4.8769 || dom: 0.0024 || loss: 6.9872 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 1100 || loc: 2.1364 || conf: 5.0910 || dom: 0.0037 || loss: 7.2310 ||\n",
      "\n",
      "Timer: 0.1952 sec.\n",
      "iter : 1110 || loc: 1.9814 || conf: 4.8967 || dom: 0.0020 || loss: 6.8801 ||\n",
      "\n",
      "Timer: 0.2078 sec.\n",
      "iter : 1120 || loc: 2.4237 || conf: 4.5224 || dom: 0.0018 || loss: 6.9479 ||\n",
      "\n",
      "Timer: 0.2047 sec.\n",
      "iter : 1130 || loc: 1.9788 || conf: 4.4637 || dom: 0.0019 || loss: 6.4445 ||\n",
      "\n",
      "Timer: 0.2054 sec.\n",
      "iter : 1140 || loc: 2.4996 || conf: 4.4858 || dom: 0.0018 || loss: 6.9872 ||\n",
      "\n",
      "Timer: 0.2029 sec.\n",
      "iter : 1150 || loc: 1.9880 || conf: 4.1471 || dom: 0.0024 || loss: 6.1374 ||\n",
      "\n",
      "Timer: 0.1972 sec.\n",
      "iter : 1160 || loc: 2.0419 || conf: 4.9719 || dom: 0.0019 || loss: 7.0157 ||\n",
      "\n",
      "Timer: 0.2029 sec.\n",
      "iter : 1170 || loc: 1.8663 || conf: 4.5170 || dom: 0.0019 || loss: 6.3853 ||\n",
      "\n",
      "Timer: 0.2055 sec.\n",
      "iter : 1180 || loc: 2.0801 || conf: 4.6242 || dom: 0.0026 || loss: 6.7069 ||\n",
      "\n",
      "Timer: 0.2058 sec.\n",
      "iter : 1190 || loc: 1.7637 || conf: 4.7321 || dom: 0.0031 || loss: 6.4989 ||\n",
      "\n",
      "Timer: 0.2030 sec.\n",
      "iter : 1200 || loc: 2.5631 || conf: 4.5098 || dom: 0.0019 || loss: 7.0748 ||\n",
      "\n",
      "Timer: 0.2024 sec.\n",
      "iter : 1210 || loc: 2.2739 || conf: 4.5564 || dom: 0.0023 || loss: 6.8326 ||\n",
      "\n",
      "Timer: 0.2027 sec.\n",
      "iter : 1220 || loc: 2.7271 || conf: 4.1839 || dom: 0.0023 || loss: 6.9132 ||\n",
      "\n",
      "Timer: 0.2036 sec.\n",
      "iter : 1230 || loc: 1.9154 || conf: 4.7127 || dom: 0.0026 || loss: 6.6308 ||\n",
      "\n",
      "Timer: 0.2089 sec.\n",
      "iter : 1240 || loc: 2.7024 || conf: 4.8723 || dom: 0.0019 || loss: 7.5766 ||\n",
      "\n",
      "Timer: 0.2125 sec.\n",
      "iter : 1250 || loc: 2.6883 || conf: 4.6259 || dom: 0.0020 || loss: 7.3162 ||\n",
      "\n",
      "Timer: 0.1956 sec.\n",
      "iter : 1260 || loc: 1.7992 || conf: 4.6542 || dom: 0.0028 || loss: 6.4562 ||\n",
      "\n",
      "Timer: 0.1979 sec.\n",
      "iter : 1270 || loc: 1.9491 || conf: 4.4681 || dom: 0.0023 || loss: 6.4195 ||\n",
      "\n",
      "Timer: 0.1985 sec.\n",
      "iter : 1280 || loc: 1.9548 || conf: 4.2725 || dom: 0.0021 || loss: 6.2295 ||\n",
      "\n",
      "Timer: 0.2068 sec.\n",
      "iter : 1290 || loc: 1.9269 || conf: 4.4346 || dom: 0.0021 || loss: 6.3636 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 1300 || loc: 1.7638 || conf: 4.1028 || dom: 0.0023 || loss: 5.8689 ||\n",
      "\n",
      "Timer: 0.2053 sec.\n",
      "iter : 1310 || loc: 2.0594 || conf: 4.4502 || dom: 0.0017 || loss: 6.5113 ||\n",
      "\n",
      "Timer: 0.2005 sec.\n",
      "iter : 1320 || loc: 2.0191 || conf: 3.7924 || dom: 0.0020 || loss: 5.8134 ||\n",
      "\n",
      "Timer: 0.1962 sec.\n",
      "iter : 1330 || loc: 1.9296 || conf: 4.4065 || dom: 0.0019 || loss: 6.3380 ||\n",
      "\n",
      "Timer: 0.1989 sec.\n",
      "iter : 1340 || loc: 1.9960 || conf: 4.6073 || dom: 0.0017 || loss: 6.6051 ||\n",
      "\n",
      "Timer: 0.2010 sec.\n",
      "iter : 1350 || loc: 1.8879 || conf: 3.9259 || dom: 0.0028 || loss: 5.8166 ||\n",
      "\n",
      "Timer: 0.1991 sec.\n",
      "iter : 1360 || loc: 2.2391 || conf: 4.2995 || dom: 0.0021 || loss: 6.5407 ||\n",
      "\n",
      "Timer: 0.1939 sec.\n",
      "iter : 1370 || loc: 2.2616 || conf: 4.7385 || dom: 0.0023 || loss: 7.0023 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 1380 || loc: 2.2068 || conf: 4.0512 || dom: 0.0022 || loss: 6.2602 ||\n",
      "\n",
      "Timer: 0.2042 sec.\n",
      "iter : 1390 || loc: 1.8465 || conf: 4.4784 || dom: 0.0030 || loss: 6.3278 ||\n",
      "\n",
      "Timer: 0.2021 sec.\n",
      "iter : 1400 || loc: 1.6333 || conf: 4.7697 || dom: 0.0024 || loss: 6.4055 ||\n",
      "\n",
      "Timer: 0.1996 sec.\n",
      "iter : 1410 || loc: 1.6633 || conf: 4.1723 || dom: 0.0026 || loss: 5.8382 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 1420 || loc: 1.8235 || conf: 5.3287 || dom: 0.0023 || loss: 7.1545 ||\n",
      "\n",
      "Timer: 0.2059 sec.\n",
      "iter : 1430 || loc: 2.1415 || conf: 4.8481 || dom: 0.0028 || loss: 6.9923 ||\n",
      "\n",
      "Timer: 0.1996 sec.\n",
      "iter : 1440 || loc: 1.8255 || conf: 3.8980 || dom: 0.0029 || loss: 5.7265 ||\n",
      "\n",
      "Timer: 0.1952 sec.\n",
      "iter : 1450 || loc: 2.3634 || conf: 4.9825 || dom: 0.0031 || loss: 7.3490 ||\n",
      "\n",
      "Timer: 0.2017 sec.\n",
      "iter : 1460 || loc: 1.6407 || conf: 4.6110 || dom: 0.0019 || loss: 6.2536 ||\n",
      "\n",
      "Timer: 0.1985 sec.\n",
      "iter : 1470 || loc: 2.0540 || conf: 4.0340 || dom: 0.0019 || loss: 6.0900 ||\n",
      "\n",
      "Timer: 0.1949 sec.\n",
      "iter : 1480 || loc: 1.9576 || conf: 4.0637 || dom: 0.0031 || loss: 6.0244 ||\n",
      "\n",
      "Timer: 0.1984 sec.\n",
      "iter : 1490 || loc: 2.0398 || conf: 3.7469 || dom: 0.0020 || loss: 5.7888 ||\n",
      "\n",
      "Timer: 0.2044 sec.\n",
      "iter : 1500 || loc: 2.3812 || conf: 4.8884 || dom: 0.0021 || loss: 7.2718 ||\n",
      "\n",
      "Timer: 0.2060 sec.\n",
      "iter : 1510 || loc: 2.2556 || conf: 4.9993 || dom: 0.0019 || loss: 7.2568 ||\n",
      "\n",
      "Timer: 0.2027 sec.\n",
      "iter : 1520 || loc: 2.4362 || conf: 4.3641 || dom: 0.0021 || loss: 6.8024 ||\n",
      "\n",
      "Timer: 0.2001 sec.\n",
      "iter : 1530 || loc: 2.3628 || conf: 4.1291 || dom: 0.0026 || loss: 6.4944 ||\n",
      "\n",
      "Timer: 0.1999 sec.\n",
      "iter : 1540 || loc: 2.0179 || conf: 4.2342 || dom: 0.0018 || loss: 6.2539 ||\n",
      "\n",
      "Timer: 0.2045 sec.\n",
      "iter : 1550 || loc: 2.0574 || conf: 4.3961 || dom: 0.0028 || loss: 6.4563 ||\n",
      "\n",
      "Timer: 0.2035 sec.\n",
      "iter : 1560 || loc: 1.8194 || conf: 4.6834 || dom: 0.0021 || loss: 6.5049 ||\n",
      "\n",
      "Timer: 0.1954 sec.\n",
      "iter : 1570 || loc: 2.0556 || conf: 4.5651 || dom: 0.0019 || loss: 6.6226 ||\n",
      "\n",
      "Timer: 0.2057 sec.\n",
      "iter : 1580 || loc: 1.8927 || conf: 5.0033 || dom: 0.0022 || loss: 6.8982 ||\n",
      "\n",
      "Timer: 0.1998 sec.\n",
      "iter : 1590 || loc: 1.9805 || conf: 4.3755 || dom: 0.0025 || loss: 6.3585 ||\n",
      "\n",
      "Timer: 0.2025 sec.\n",
      "iter : 1600 || loc: 2.0716 || conf: 4.0081 || dom: 0.0018 || loss: 6.0815 ||\n",
      "\n",
      "Timer: 0.2037 sec.\n",
      "iter : 1610 || loc: 2.2626 || conf: 4.6325 || dom: 0.0020 || loss: 6.8971 ||\n",
      "\n",
      "Timer: 0.2096 sec.\n",
      "iter : 1620 || loc: 2.2456 || conf: 4.5019 || dom: 0.0015 || loss: 6.7490 ||\n",
      "\n",
      "Timer: 0.2056 sec.\n",
      "iter : 1630 || loc: 2.2967 || conf: 4.5027 || dom: 0.0017 || loss: 6.8011 ||\n",
      "\n",
      "Timer: 0.2083 sec.\n",
      "iter : 1640 || loc: 1.9827 || conf: 4.0158 || dom: 0.0017 || loss: 6.0001 ||\n",
      "\n",
      "Timer: 0.2015 sec.\n",
      "iter : 1650 || loc: 1.7916 || conf: 4.5900 || dom: 0.0036 || loss: 6.3852 ||\n",
      "\n",
      "Timer: 0.2029 sec.\n",
      "iter : 1660 || loc: 2.1380 || conf: 5.0064 || dom: 0.0022 || loss: 7.1466 ||\n",
      "\n",
      "Timer: 0.1984 sec.\n",
      "iter : 1670 || loc: 2.1499 || conf: 4.2933 || dom: 0.0023 || loss: 6.4455 ||\n",
      "\n",
      "Timer: 0.1981 sec.\n",
      "iter : 1680 || loc: 2.1197 || conf: 4.1392 || dom: 0.0018 || loss: 6.2608 ||\n",
      "\n",
      "Timer: 0.2004 sec.\n",
      "iter : 1690 || loc: 1.6011 || conf: 4.0602 || dom: 0.0030 || loss: 5.6642 ||\n",
      "\n",
      "Timer: 0.2194 sec.\n",
      "iter : 1700 || loc: 2.2407 || conf: 4.4896 || dom: 0.0021 || loss: 6.7323 ||\n",
      "\n",
      "Timer: 0.2058 sec.\n",
      "iter : 1710 || loc: 2.0511 || conf: 4.1680 || dom: 0.0024 || loss: 6.2216 ||\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 0.2030 sec.\n",
      "iter : 1720 || loc: 2.3592 || conf: 4.6082 || dom: 0.0025 || loss: 6.9699 ||\n",
      "\n",
      "Timer: 0.1964 sec.\n",
      "iter : 1730 || loc: 1.6881 || conf: 4.9300 || dom: 0.0025 || loss: 6.6206 ||\n",
      "\n",
      "Timer: 0.1947 sec.\n",
      "iter : 1740 || loc: 2.2603 || conf: 4.6846 || dom: 0.0020 || loss: 6.9470 ||\n",
      "\n",
      "Timer: 0.1963 sec.\n",
      "iter : 1750 || loc: 2.1926 || conf: 3.8357 || dom: 0.0019 || loss: 6.0302 ||\n",
      "\n",
      "Timer: 0.1943 sec.\n",
      "iter : 1760 || loc: 2.0160 || conf: 4.5423 || dom: 0.0023 || loss: 6.5606 ||\n",
      "\n",
      "Timer: 0.2031 sec.\n",
      "iter : 1770 || loc: 2.4671 || conf: 4.5771 || dom: 0.0028 || loss: 7.0470 ||\n",
      "\n",
      "Timer: 0.2052 sec.\n",
      "iter : 1780 || loc: 1.5742 || conf: 4.2502 || dom: 0.0021 || loss: 5.8266 ||\n",
      "\n",
      "Timer: 0.2066 sec.\n",
      "iter : 1790 || loc: 1.8776 || conf: 4.8358 || dom: 0.0024 || loss: 6.7158 ||\n",
      "\n",
      "Timer: 0.2002 sec.\n",
      "iter : 1800 || loc: 1.9287 || conf: 4.5160 || dom: 0.0020 || loss: 6.4466 ||\n",
      "\n",
      "Timer: 0.1971 sec.\n",
      "iter : 1810 || loc: 2.0531 || conf: 4.1307 || dom: 0.0021 || loss: 6.1859 ||\n",
      "\n",
      "Timer: 0.2027 sec.\n",
      "iter : 1820 || loc: 1.8115 || conf: 4.1847 || dom: 0.0034 || loss: 5.9996 ||\n",
      "\n",
      "Timer: 0.1984 sec.\n",
      "iter : 1830 || loc: 1.8446 || conf: 4.4292 || dom: 0.0024 || loss: 6.2762 ||\n",
      "\n",
      "Timer: 0.1985 sec.\n",
      "iter : 1840 || loc: 1.8405 || conf: 4.7715 || dom: 0.0024 || loss: 6.6145 ||\n",
      "\n",
      "Timer: 0.2035 sec.\n",
      "iter : 1850 || loc: 2.1802 || conf: 4.2188 || dom: 0.0014 || loss: 6.4003 ||\n",
      "\n",
      "Timer: 0.1952 sec.\n",
      "iter : 1860 || loc: 2.2378 || conf: 3.8720 || dom: 0.0022 || loss: 6.1121 ||\n",
      "\n",
      "Timer: 0.1956 sec.\n",
      "iter : 1870 || loc: 2.1433 || conf: 5.3504 || dom: 0.0019 || loss: 7.4956 ||\n",
      "\n",
      "Timer: 0.1984 sec.\n",
      "iter : 1880 || loc: 1.9749 || conf: 4.4186 || dom: 0.0022 || loss: 6.3958 ||\n",
      "\n",
      "Timer: 0.2129 sec.\n",
      "iter : 1890 || loc: 2.0864 || conf: 4.6230 || dom: 0.0021 || loss: 6.7116 ||\n",
      "\n",
      "Timer: 0.1970 sec.\n",
      "iter : 1900 || loc: 2.0161 || conf: 4.1913 || dom: 0.0025 || loss: 6.2099 ||\n",
      "\n",
      "Timer: 0.2028 sec.\n",
      "iter : 1910 || loc: 1.8438 || conf: 4.7455 || dom: 0.0025 || loss: 6.5919 ||\n",
      "\n",
      "Timer: 0.2007 sec.\n",
      "iter : 1920 || loc: 1.6073 || conf: 3.6517 || dom: 0.0019 || loss: 5.2609 ||\n",
      "\n",
      "Timer: 0.2014 sec.\n",
      "iter : 1930 || loc: 1.9394 || conf: 4.0011 || dom: 0.0019 || loss: 5.9424 ||\n",
      "\n",
      "Timer: 0.1990 sec.\n",
      "iter : 1940 || loc: 1.9353 || conf: 4.0329 || dom: 0.0035 || loss: 5.9717 ||\n",
      "\n",
      "Timer: 0.2026 sec.\n",
      "iter : 1950 || loc: 2.1389 || conf: 4.0200 || dom: 0.0022 || loss: 6.1612 ||\n",
      "\n",
      "Timer: 0.2104 sec.\n",
      "iter : 1960 || loc: 2.1901 || conf: 4.3797 || dom: 0.0028 || loss: 6.5727 ||\n",
      "\n",
      "Timer: 0.1991 sec.\n",
      "iter : 1970 || loc: 1.5013 || conf: 4.0335 || dom: 0.0028 || loss: 5.5376 ||\n",
      "\n",
      "Timer: 0.2028 sec.\n",
      "iter : 1980 || loc: 2.1049 || conf: 4.5967 || dom: 0.0023 || loss: 6.7038 ||\n",
      "\n",
      "Timer: 0.1951 sec.\n",
      "iter : 1990 || loc: 2.0683 || conf: 4.6366 || dom: 0.0033 || loss: 6.7082 ||\n",
      "\n",
      "Timer: 0.1950 sec.\n",
      "iter : 2000 || loc: 1.7726 || conf: 4.5358 || dom: 0.0032 || loss: 6.3116 ||\n",
      "\n",
      "Saving state, iter: 2000\n",
      "Timer: 0.2037 sec.\n",
      "iter : 2010 || loc: 2.2306 || conf: 4.7233 || dom: 0.0021 || loss: 6.9560 ||\n",
      "\n",
      "Timer: 0.2023 sec.\n",
      "iter : 2020 || loc: 1.7739 || conf: 4.3738 || dom: 0.0025 || loss: 6.1501 ||\n",
      "\n",
      "Timer: 0.1982 sec.\n",
      "iter : 2030 || loc: 1.7870 || conf: 4.3043 || dom: 0.0018 || loss: 6.0931 ||\n",
      "\n",
      "Timer: 0.2028 sec.\n",
      "iter : 2040 || loc: 1.9729 || conf: 4.6703 || dom: 0.0017 || loss: 6.6449 ||\n",
      "\n",
      "Timer: 0.1981 sec.\n",
      "iter : 2050 || loc: 2.2982 || conf: 4.3436 || dom: 0.0034 || loss: 6.6452 ||\n",
      "\n",
      "Timer: 0.2008 sec.\n",
      "iter : 2060 || loc: 2.2314 || conf: 4.6998 || dom: 0.0024 || loss: 6.9336 ||\n",
      "\n",
      "Timer: 0.1955 sec.\n",
      "iter : 2070 || loc: 1.5809 || conf: 4.1177 || dom: 0.0020 || loss: 5.7006 ||\n",
      "\n",
      "Timer: 0.1941 sec.\n",
      "iter : 2080 || loc: 1.8809 || conf: 4.3777 || dom: 0.0026 || loss: 6.2612 ||\n",
      "\n",
      "Timer: 0.2151 sec.\n",
      "iter : 2090 || loc: 1.9296 || conf: 4.3573 || dom: 0.0022 || loss: 6.2891 ||\n",
      "\n",
      "Timer: 0.1966 sec.\n",
      "iter : 2100 || loc: 1.8591 || conf: 4.8240 || dom: 0.0027 || loss: 6.6858 ||\n",
      "\n",
      "Timer: 0.1970 sec.\n",
      "iter : 2110 || loc: 1.9118 || conf: 4.3983 || dom: 0.0015 || loss: 6.3116 ||\n",
      "\n",
      "Timer: 0.2000 sec.\n",
      "iter : 2120 || loc: 1.8821 || conf: 4.0654 || dom: 0.0019 || loss: 5.9494 ||\n",
      "\n",
      "Timer: 0.1996 sec.\n",
      "iter : 2130 || loc: 1.7710 || conf: 3.7504 || dom: 0.0019 || loss: 5.5234 ||\n",
      "\n",
      "Timer: 0.2020 sec.\n",
      "iter : 2140 || loc: 1.6512 || conf: 4.2687 || dom: 0.0029 || loss: 5.9228 ||\n",
      "\n",
      "Timer: 0.2105 sec.\n",
      "iter : 2150 || loc: 2.2970 || conf: 3.6244 || dom: 0.0017 || loss: 5.9231 ||\n",
      "\n",
      "Timer: 0.2015 sec.\n",
      "iter : 2160 || loc: 1.8488 || conf: 4.3494 || dom: 0.0029 || loss: 6.2011 ||\n",
      "\n",
      "Timer: 0.1990 sec.\n",
      "iter : 2170 || loc: 2.1434 || conf: 4.5730 || dom: 0.0021 || loss: 6.7184 ||\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    # loss counters\n",
    "    loc_loss = 0  # epoch\n",
    "    conf_loss = 0\n",
    "    epoch = 0\n",
    "    print('Loading Dataset...')\n",
    "\n",
    "#CHANGE\n",
    "    dataset = commonDataset(voc_root, train_sets, ssd_dim, means,\n",
    "                cocoimg, annFile)\n",
    "    #dataset = VOCDetection(voc_root, train_sets, SSDAugmentation(\n",
    "    #    ssd_dim, means), AnnotationTransform())\n",
    "\n",
    "    epoch_size = len(dataset) // batch_size\n",
    "    print('Training SSD on', dataset.name)\n",
    "    step_index = 0\n",
    "    if visdom:\n",
    "        # initialize visdom loss plot\n",
    "        lot = viz.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1, 3)).cpu(),\n",
    "            opts=dict(\n",
    "                xlabel='Iteration',\n",
    "                ylabel='Loss',\n",
    "                title='Current SSD Training Loss',\n",
    "                legend=['Loc Loss', 'Conf Loss', 'Loss']\n",
    "            )\n",
    "        )\n",
    "        epoch_lot = viz.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1, 3)).cpu(),\n",
    "            opts=dict(\n",
    "                xlabel='Epoch',\n",
    "                ylabel='Loss',\n",
    "                title='Epoch SSD Training Loss',\n",
    "                legend=['Loc Loss', 'Conf Loss', 'Loss']\n",
    "            )\n",
    "        )\n",
    "    batch_iterator = None\n",
    "    data_loader = data.DataLoader(dataset, batch_size, num_workers=num_workers,\n",
    "                                  shuffle=True, collate_fn=detection_collate, pin_memory=True)\n",
    "    for iteration in range(start_iter, max_iter):\n",
    "        if (not batch_iterator) or (iteration % epoch_size == 0):\n",
    "            # create batch iterator\n",
    "            batch_iterator = iter(data_loader)\n",
    "        if iteration in stepvalues:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, gamma, step_index)\n",
    "            if visdom:\n",
    "                viz.line(\n",
    "                    X=torch.ones((1, 3)).cpu() * epoch,\n",
    "                    Y=torch.Tensor([loc_loss, conf_loss,\n",
    "                        loc_loss + conf_loss]).unsqueeze(0).cpu() / epoch_size,\n",
    "                    win=epoch_lot,\n",
    "                    update='append'\n",
    "                )\n",
    "            # reset epoch loss counters\n",
    "            loc_loss = 0\n",
    "            conf_loss = 0\n",
    "            epoch += 1\n",
    "\n",
    "        # load train data\n",
    "        images, targets = next(batch_iterator)\n",
    "\n",
    "        if cuda:\n",
    "            images = Variable(images.cuda())\n",
    "            targets = [Variable(anno.cuda(), volatile=True) for anno in targets]\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            targets = [Variable(anno, volatile=True) for anno in targets]\n",
    "        # forward\n",
    "        t0 = time.time()\n",
    "        out = net(images)\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "#CHANGE\n",
    "        loss_l, loss_c, loss_d = criterion(out, targets)\n",
    "        loss = loss_l + loss_c + loss_d\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        loc_loss += loss_l.data[0]\n",
    "        conf_loss += loss_c.data[0]\n",
    "        if iteration % 10 == 0:\n",
    "            print('Timer: %.4f sec.' % (t1 - t0))\n",
    "            print(\"iter : \"+repr(iteration)+\" || loc: %.4f || conf: %.4f || dom: %.4f || loss: %.4f ||\\n\" %\n",
    "                       (loss_l.data[0], loss_c.data[0], loss_d.data[0], loss.data[0]) )\n",
    "            if visdom and send_images_to_visdom:\n",
    "                random_batch_index = np.random.randint(images.size(0))\n",
    "                viz.image(images.data[random_batch_index].cpu().numpy())\n",
    "            if logTensorboard:\n",
    "                info = {\n",
    "                    'loc_loss' : loss_l.data[0],\n",
    "                    'conf_loss' : loss_c.data[0],\n",
    "                'domain_loss' : loss_d.data[0],\n",
    "                'loss' : loss.data[0]\n",
    "                    }\n",
    "                \n",
    "                for tag, value in info.items():\n",
    "                    logger.scalar_summary(tag, value, iteration)\n",
    "                \n",
    "                def to_np(x):\n",
    "                    return x.data.cpu().numpy()\n",
    "                \n",
    "                for tag, value in net.named_parameters():\n",
    "                    tag = tag.replace('.','/')\n",
    "                    logger.histo_summary(tag, to_np(value), iteration)\n",
    "                    logger.histo_summary(tag+'/grad', to_np(value.grad), iteration)\n",
    "                    \n",
    "\n",
    "        if iteration % 2000 == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(ssd_net.state_dict(), 'weights/ssd300_0712_COCO14_' +\n",
    "                       repr(iteration) + '.pth')\n",
    "    torch.save(ssd_net.state_dict(), save_folder + '' + version + '.pth')\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
