{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:21:05.609128Z",
     "start_time": "2018-01-12T09:21:05.600306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMSCOCO14 dataset classes\\nMade using voc0712.py as reference.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "MSCOCO14 dataset classes\n",
    "Made using voc0712.py as reference.\n",
    "This notebook itself is not used. A python script is generated from it\n",
    "and then placed inside data/ director for loading MSCOCO14 dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:13:13.076451Z",
     "start_time": "2018-01-12T09:13:01.987331Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:13:15.451704Z",
     "start_time": "2018-01-12T09:13:15.448924Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#path to coco PythonAPI\n",
    "# also contain MSCOCO14 dataset\n",
    "pycocoapi = \"/new_data/gpu/utkrsh/coco/PythonAPI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:13:16.787431Z",
     "start_time": "2018-01-12T09:13:16.783126Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(pycocoapi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:13:23.803398Z",
     "start_time": "2018-01-12T09:13:20.324549Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:13:26.416437Z",
     "start_time": "2018-01-12T09:13:26.410295Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COMMON_CLASSES = ('person', 'bicycle', 'car',\n",
    "                  'bus', 'train', 'boat',\n",
    "                   'bird', 'cat', 'dog',\n",
    "                   'horse', 'sheep', 'cow',\n",
    "                   'bottle', 'chair', 'airplane',\n",
    "                 'dining table', 'potted plant', 'tv',\n",
    "                 'motorcycle', 'couch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:13:28.983496Z",
     "start_time": "2018-01-12T09:13:28.853994Z"
    },
    "code_folding": [
     8,
     18,
     26,
     39,
     49
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MSCOCODetection(data.Dataset):\n",
    "    def __init__(self,image_root,ann_root,transform=None,target_transform=None,\n",
    "                dataset_name=\"COCO2014\"):\n",
    "        self.image_root = image_root\n",
    "        self.ann_root = ann_root\n",
    "        self.transform = transform\n",
    "        self.target_transform=target_transform\n",
    "        self.name=dataset_name\n",
    "        self.COMMON_CLASSES = ('person', 'bicycle', 'car',\n",
    "                  'bus', 'train', 'boat',\n",
    "                   'bird', 'cat', 'dog',\n",
    "                   'horse', 'sheep', 'cow',\n",
    "                   'bottle', 'chair', 'airplane',\n",
    "                 'dining table', 'potted plant', 'tv',\n",
    "                 'motorcycle', 'couch')\n",
    "        self.coco = COCO(ann_root)\n",
    "        self.catIds = self.coco.getCatIds(catNms=self.COMMON_CLASSES)\n",
    "        self.imgIdList = list() #list of images with given categories\n",
    "        for i in self.catIds:\n",
    "            self.imgIdList += self.coco.catToImgs[i]\n",
    "        self.imgIdList = list(set(self.imgIdList))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ''' insert return statement '''\n",
    "        im, gt, _, _ = self.pull_item(index)\n",
    "        \n",
    "    def __len__(self):\n",
    "        ''' return the number of examples '''\n",
    "        return len(self.imgIdList)\n",
    "    \n",
    "    def pull_item(self,index):\n",
    "        imgObj = self.coco.loadImgs(self.imgIdList[index])[0] #return list\n",
    "            #containining dictionary object\n",
    "        img = cv2.imread(self.image_root+imgObj['file_name']) #numpy array\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target, width, height)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            target = np.array(target)\n",
    "            img, boxes, labels = self.transform(img, target[:, :4], target[:, 4])\n",
    "            # to rgb\n",
    "            img = img[:, :, (2, 1, 0)]\n",
    "            # img = img.transpose(2, 0, 1)\n",
    "            target = np.hstack((boxes, np.expand_dims(labels, axis=1)))\n",
    "        return torch.from_numpy(img).permute(2, 0, 1), target, height, width\n",
    "        # return torch.from_numpy(img), target, height, width\n",
    "        \n",
    "    def pull_image(self, index):\n",
    "        '''Returns the original image object at index in PIL form\n",
    "\n",
    "        Note: not using self.__getitem__(), as any transformations passed in\n",
    "        could mess up this functionality.\n",
    "\n",
    "        Argument:\n",
    "            index (int): index of img to show\n",
    "        Return:\n",
    "            PIL img\n",
    "        '''\n",
    "        imgObj = self.coco.loadImgs(self.imgIdList[index])[0]\n",
    "        return cv2.imread(self.image_root+imgObj['file_name'],\n",
    "                          cv2.IMREAD_COLOR)\n",
    "\n",
    "    def pull_anno(self, index):\n",
    "        '''Returns the original annotation of image at index\n",
    "\n",
    "        Note: not using self.__getitem__(), as any transformations passed in\n",
    "        could mess up this functionality.\n",
    "\n",
    "        Argument:\n",
    "            index (int): index of img to get annotation of\n",
    "        Return:\n",
    "            list:  [img_id, [(label, bbox coords),...]]\n",
    "                eg: ('001718', [('dog', (96, 13, 438, 332))])\n",
    "        '''\n",
    "        imgObj = self.coco.loadImgs(self.imgIdList[index])[0]\n",
    "        # returns dictionary object\n",
    "        annId = self.coco.getAnnIds(imgIds=imgObj['id'], \n",
    "                                    catIds=self.catIds, iscrowd=None)\n",
    "        ann = self.coco.loadAnns(annId) #return list of annotations\n",
    "        gt = self.target_transform(anno, 1, 1)\n",
    "        return imgObj['id'], gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-12T09:13:31.025833Z",
     "start_time": "2018-01-12T09:13:31.000987Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class COCOAnnotationTransform(object):\n",
    "    \"\"\"Transforms a VOC annotation into a Tensor of bbox coords and label index\n",
    "    Initilized with a dictionary lookup of classnames to indexes\n",
    "\n",
    "    Arguments:\n",
    "        class_to_ind (dict, optional): dictionary lookup of classnames -> indexes\n",
    "            (default: alphabetic indexing of VOC's 20 classes)\n",
    "        keep_difficult (bool, optional): keep difficult instances or not\n",
    "            (default: False)\n",
    "        height (int): height\n",
    "        width (int): width\n",
    "    \"\"\"\n",
    "\n",
    "    #def __init__(self, class_to_ind=None, keep_difficult=False):\n",
    "\n",
    "    def __call__(self, target, width, height):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            target (annotation) : the target annotation to be made usable\n",
    "                will be an ET.Element\n",
    "        Returns:\n",
    "            a list containing lists of bounding boxes  [bbox coords, class name]\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for i in target:\n",
    "            bbox = i['bbox']\n",
    "\n",
    "            #bbox format is [xmin, ymin, width, height]\n",
    "            bbox[2] = bbox[2]+bbox[0]\n",
    "            bbox[3] = bbox[3]+bbox[1]\n",
    "            bbox[0] /= width\n",
    "            bbox[2] /= width\n",
    "            bbox[1] /= height\n",
    "            bbox[3] /= height\n",
    "            bbox.append(i['category_id'])\n",
    "            res += [bbox]\n",
    "           \n",
    "        return res  # [[xmin, ymin, xmax, ymax, label_ind], ... ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
