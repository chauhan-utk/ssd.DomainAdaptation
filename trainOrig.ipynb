{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for the original dataset loader file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T13:30:55.650186Z",
     "start_time": "2018-02-07T13:30:50.856028Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "\n",
    "from data import v2, v1, AnnotationTransform, VOCDetection, detection_collate, VOCroot, VOC_CLASSES\n",
    "from data import v2, v1, detection_collate\n",
    "#from data import MSCOCODetection, COCOAnnotationTransform\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from logger import Logger\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-06T17:50:51.276367Z",
     "start_time": "2018-02-06T17:50:51.259703Z"
    }
   },
   "source": [
    "%set_env CUDA_DEVICE_ORDER = PCI_BUS_ID\n",
    "%set_env CUDA_VISIBLE_DEVICES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T13:30:55.670453Z",
     "start_time": "2018-02-07T13:30:55.654455Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version = 'v2'\n",
    "basenet = 'vgg16_reducedfc.pth'\n",
    "jaccard_threshold = 0.5\n",
    "batch_size = 32\n",
    "resume = None\n",
    "num_workers = 4\n",
    "iterations = 120000\n",
    "start_iter = 0\n",
    "cuda = True\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "gamma = 0.1\n",
    "log_iters = False\n",
    "visdom = False\n",
    "send_images_to_visdom = True\n",
    "save_folder = 'weights/'\n",
    "voc_root = VOCroot\n",
    "log_tf = True\n",
    "log_tf_dir = '.logs/run1_onlyVOC07_baseline_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T13:30:55.999268Z",
     "start_time": "2018-02-07T13:30:55.672144Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = Logger(log_tf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T13:30:58.273689Z",
     "start_time": "2018-02-07T13:30:56.002130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base network...\n",
      "Initializing weights...\n"
     ]
    }
   ],
   "source": [
    "if cuda and torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "cfg = (v1, v2)[version == 'v2']\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "train_sets = [('2007', 'trainval')]\n",
    "# train_sets = 'train'\n",
    "ssd_dim = 300  # only support 300 now\n",
    "means = (104, 117, 123)  # only support voc now\n",
    "num_classes = len(VOC_CLASSES) + 1\n",
    "batch_size = batch_size\n",
    "accum_batch_size = 32\n",
    "iter_size = accum_batch_size / batch_size\n",
    "max_iter = 120000\n",
    "weight_decay = 0.0005\n",
    "stepvalues = (80000, 100000, 120000)\n",
    "gamma = 0.1\n",
    "momentum = 0.9\n",
    "\n",
    "if visdom:\n",
    "    import visdom\n",
    "    viz = visdom.Visdom()\n",
    "\n",
    "ssd_net = build_ssd('train', 300, num_classes)\n",
    "net = ssd_net\n",
    "\n",
    "if False:\n",
    "    net = torch.nn.DataParallel(ssd_net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if resume:\n",
    "    print('Resuming training, loading {}...'.format(resume))\n",
    "    ssd_net.load_weights(resume)\n",
    "else:\n",
    "    vgg_weights = torch.load(save_folder + basenet)\n",
    "    print('Loading base network...')\n",
    "    ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "if cuda and torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "if not resume:\n",
    "    print('Initializing weights...')\n",
    "    # initialize newly added layers' weights with xavier method\n",
    "    ssd_net.extras.apply(weights_init)\n",
    "    ssd_net.loc.apply(weights_init)\n",
    "    ssd_net.conf.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T13:30:58.462201Z",
     "start_time": "2018-02-07T13:30:58.275758Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = MultiBoxLoss(num_classes, 0.5, True, 0, True, 3, 0.5, False, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T13:30:58.787773Z",
     "start_time": "2018-02-07T13:30:58.464829Z"
    },
    "code_folding": [
     14,
     46,
     83,
     86
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    # loss counters\n",
    "    loc_loss = 0  # epoch\n",
    "    conf_loss = 0\n",
    "    epoch = 0\n",
    "    print('Loading Dataset...')\n",
    "\n",
    "    dataset = VOCDetection(voc_root, train_sets, SSDAugmentation(\n",
    "        ssd_dim, means), AnnotationTransform())\n",
    "\n",
    "    epoch_size = len(dataset) // batch_size\n",
    "    print('Training SSD on', dataset.name)\n",
    "    step_index = 0\n",
    "    if visdom:\n",
    "        # initialize visdom loss plot\n",
    "        lot = viz.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1, 3)).cpu(),\n",
    "            opts=dict(\n",
    "                xlabel='Iteration',\n",
    "                ylabel='Loss',\n",
    "                title='Current SSD Training Loss',\n",
    "                legend=['Loc Loss', 'Conf Loss', 'Loss']\n",
    "            )\n",
    "        )\n",
    "        epoch_lot = viz.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1, 3)).cpu(),\n",
    "            opts=dict(\n",
    "                xlabel='Epoch',\n",
    "                ylabel='Loss',\n",
    "                title='Epoch SSD Training Loss',\n",
    "                legend=['Loc Loss', 'Conf Loss', 'Loss']\n",
    "            )\n",
    "        )\n",
    "    batch_iterator = None\n",
    "    data_loader = data.DataLoader(dataset, batch_size, num_workers=num_workers,\n",
    "                                  shuffle=True, collate_fn=detection_collate, pin_memory=True)\n",
    "    for iteration in range(start_iter, max_iter):\n",
    "        if (not batch_iterator) or (iteration % epoch_size == 0):\n",
    "            # create batch iterator\n",
    "            batch_iterator = iter(data_loader)\n",
    "        if iteration in stepvalues:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, gamma, step_index)\n",
    "            if visdom:\n",
    "                viz.line(\n",
    "                    X=torch.ones((1, 3)).cpu() * epoch,\n",
    "                    Y=torch.Tensor([loc_loss, conf_loss,\n",
    "                        loc_loss + conf_loss]).unsqueeze(0).cpu() / epoch_size,\n",
    "                    win=epoch_lot,\n",
    "                    update='append'\n",
    "                )\n",
    "            # reset epoch loss counters\n",
    "            loc_loss = 0\n",
    "            conf_loss = 0\n",
    "            epoch += 1\n",
    "\n",
    "        # load train data\n",
    "        images, targets = next(batch_iterator)\n",
    "\n",
    "        if cuda:\n",
    "            images = Variable(images.cuda())\n",
    "            targets = [Variable(anno.cuda(), volatile=True) for anno in targets]\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            targets = [Variable(anno, volatile=True) for anno in targets]\n",
    "        # forward\n",
    "        t0 = time.time()\n",
    "        out = net(images)\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss_l, loss_c = criterion(out, targets)\n",
    "        loss = loss_l + loss_c\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        loc_loss += loss_l.data[0]\n",
    "        conf_loss += loss_c.data[0]\n",
    "        if iteration % 10 == 0:\n",
    "            print('Timer: %.4f sec.' % (t1 - t0))\n",
    "            print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.data[0]), end=' ')\n",
    "            if visdom and send_images_to_visdom:\n",
    "                random_batch_index = np.random.randint(images.size(0))\n",
    "                viz.image(images.data[random_batch_index].cpu().numpy())\n",
    "            if log_tf:\n",
    "                info = {\n",
    "                    'conf_loss' : loss_c.data[0],\n",
    "                    'loc_loss' : loss_l.data[0],\n",
    "                    'loss' : loss.data[0]\n",
    "                }\n",
    "                for tag, val in info.items():\n",
    "                    logger.scalar_summary(tag, val, iteration)\n",
    "                \n",
    "                def to_np(x):\n",
    "                    return x.data.cpu().numpy()\n",
    "                \n",
    "                for tag, val in net.named_parameters():\n",
    "                    tag = tag.replace('.', '/')\n",
    "                    logger.histo_summary(tag, to_np(val), iteration)\n",
    "                    logger.histo_summary(tag+'/grad', to_np(val.grad), iteration)\n",
    "        if visdom:\n",
    "            viz.line(\n",
    "                X=torch.ones((1, 3)).cpu() * iteration,\n",
    "                Y=torch.Tensor([loss_l.data[0], loss_c.data[0],\n",
    "                    loss_l.data[0] + loss_c.data[0]]).unsqueeze(0).cpu(),\n",
    "                win=lot,\n",
    "                update='append'\n",
    "            )\n",
    "            # hacky fencepost solution for 0th epoch plot\n",
    "            if iteration == 0:\n",
    "                viz.line(\n",
    "                    X=torch.zeros((1, 3)).cpu(),\n",
    "                    Y=torch.Tensor([loc_loss, conf_loss,\n",
    "                        loc_loss + conf_loss]).unsqueeze(0).cpu(),\n",
    "                    win=epoch_lot,\n",
    "                    update=True\n",
    "                )\n",
    "        if iteration % 2000 == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(ssd_net.state_dict(), save_folder + 'ssd300_0712_bs_' +\n",
    "                       repr(iteration) + '.pth')\n",
    "    torch.save(ssd_net.state_dict(), save_folder + '' + version + '.pth')\n",
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T13:32:22.741788Z",
     "start_time": "2018-02-07T13:30:58.789314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "Training SSD on VOC0712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/gpu/utkrsh/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py:450: UserWarning: mask is not broadcastable to self, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return tensor.masked_fill_(mask, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer: 1.6907 sec.\n",
      "iter 0 || Loss: 26.4160 || Saving state, iter: 0\n",
      "Timer: 0.3819 sec.\n",
      "iter 10 || Loss: 15.6536 || Timer: 0.3795 sec.\n",
      "iter 20 || Loss: 17.7329 || Timer: 0.3790 sec.\n",
      "iter 30 || Loss: 16.3245 || Timer: 0.3841 sec.\n",
      "iter 40 || Loss: 13.8371 || Timer: 0.4032 sec.\n",
      "iter 50 || Loss: 55.1057 || Timer: 0.3961 sec.\n",
      "iter 60 || Loss: nan || "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "range parameter must be finite.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-93fd337a0d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-befe0100f11b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhisto_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhisto_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvisdom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/new_data/gpu/utkrsh/DomainAdaptation/logger.py\u001b[0m in \u001b[0;36mhisto_summary\u001b[0;34m(self, tag, values, step, bins)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# Create a histogram using numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Fill the fields of the histogram proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         raise ValueError(\n\u001b[0;32m--> 670\u001b[0;31m             'range parameter must be finite.')\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mmn\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: range parameter must be finite."
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
