{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for the original dataset loader file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-03T05:59:03.442742Z",
     "start_time": "2018-02-03T05:59:02.096490Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data\n",
    "\n",
    "from data import v2, v1, AnnotationTransform, VOCDetection, detection_collate, VOCroot, VOC_CLASSES\n",
    "from data import v2, v1, detection_collate\n",
    "#from data import MSCOCODetection, COCOAnnotationTransform\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version = 'v2'\n",
    "basenet = 'vgg16_reducedfc.pth'\n",
    "jaccard_threshold = 0.5\n",
    "batch_size = 32\n",
    "resume = None\n",
    "num_workers = 4\n",
    "iterations = 120000\n",
    "start_iter = 0\n",
    "cuda = True\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "gamma = 0.1\n",
    "log_iters = True\n",
    "visdom = False\n",
    "send_images_to_visdom = False\n",
    "save_folder = 'weights/'\n",
    "voc_root = VOCroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if cuda and torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "cfg = (v1, v2)[version == 'v2']\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "train_sets = [('2007', 'trainval')]\n",
    "# train_sets = 'train'\n",
    "ssd_dim = 300  # only support 300 now\n",
    "means = (104, 117, 123)  # only support voc now\n",
    "num_classes = len(VOC_CLASSES) + 1\n",
    "batch_size = batch_size\n",
    "accum_batch_size = 32\n",
    "iter_size = accum_batch_size / batch_size\n",
    "max_iter = 120000\n",
    "weight_decay = 0.0005\n",
    "stepvalues = (80000, 100000, 120000)\n",
    "gamma = 0.1\n",
    "momentum = 0.9\n",
    "\n",
    "if visdom:\n",
    "    import visdom\n",
    "    viz = visdom.Visdom()\n",
    "\n",
    "ssd_net = build_ssd('train', 300, num_classes)\n",
    "net = ssd_net\n",
    "\n",
    "if False:\n",
    "    net = torch.nn.DataParallel(ssd_net)\n",
    "\n",
    "if True:\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "if resume:\n",
    "    print('Resuming training, loading {}...'.format(resume))\n",
    "    ssd_net.load_weights(resume)\n",
    "else:\n",
    "    vgg_weights = torch.load(save_folder + basenet)\n",
    "    print('Loading base network...')\n",
    "    ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "if cuda and torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "if not resume:\n",
    "    print('Initializing weights...')\n",
    "    # initialize newly added layers' weights with xavier method\n",
    "    ssd_net.extras.apply(weights_init)\n",
    "    ssd_net.loc.apply(weights_init)\n",
    "    ssd_net.conf.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-27T06:17:18.694332Z",
     "start_time": "2018-01-27T06:17:18.686126Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=lr,\n",
    "                      momentum=momentum, weight_decay=weight_decay)\n",
    "criterion = MultiBoxLoss(num_classes, 0.5, True, 0, True, 3, 0.5, False, cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-27T06:17:26.276772Z",
     "start_time": "2018-01-27T06:17:26.157353Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    net.train()\n",
    "    # loss counters\n",
    "    loc_loss = 0  # epoch\n",
    "    conf_loss = 0\n",
    "    epoch = 0\n",
    "    print('Loading Dataset...')\n",
    "\n",
    "    dataset = VOCDetection(voc_root, train_sets, SSDAugmentation(\n",
    "        ssd_dim, means), AnnotationTransform())\n",
    "\n",
    "    epoch_size = len(dataset) // batch_size\n",
    "    print('Training SSD on', dataset.name)\n",
    "    step_index = 0\n",
    "    if visdom:\n",
    "        # initialize visdom loss plot\n",
    "        lot = viz.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1, 3)).cpu(),\n",
    "            opts=dict(\n",
    "                xlabel='Iteration',\n",
    "                ylabel='Loss',\n",
    "                title='Current SSD Training Loss',\n",
    "                legend=['Loc Loss', 'Conf Loss', 'Loss']\n",
    "            )\n",
    "        )\n",
    "        epoch_lot = viz.line(\n",
    "            X=torch.zeros((1,)).cpu(),\n",
    "            Y=torch.zeros((1, 3)).cpu(),\n",
    "            opts=dict(\n",
    "                xlabel='Epoch',\n",
    "                ylabel='Loss',\n",
    "                title='Epoch SSD Training Loss',\n",
    "                legend=['Loc Loss', 'Conf Loss', 'Loss']\n",
    "            )\n",
    "        )\n",
    "    batch_iterator = None\n",
    "    data_loader = data.DataLoader(dataset, batch_size, num_workers=num_workers,\n",
    "                                  shuffle=True, collate_fn=detection_collate, pin_memory=True)\n",
    "    for iteration in range(start_iter, max_iter):\n",
    "        if (not batch_iterator) or (iteration % epoch_size == 0):\n",
    "            # create batch iterator\n",
    "            batch_iterator = iter(data_loader)\n",
    "        if iteration in stepvalues:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, gamma, step_index)\n",
    "            if visdom:\n",
    "                viz.line(\n",
    "                    X=torch.ones((1, 3)).cpu() * epoch,\n",
    "                    Y=torch.Tensor([loc_loss, conf_loss,\n",
    "                        loc_loss + conf_loss]).unsqueeze(0).cpu() / epoch_size,\n",
    "                    win=epoch_lot,\n",
    "                    update='append'\n",
    "                )\n",
    "            # reset epoch loss counters\n",
    "            loc_loss = 0\n",
    "            conf_loss = 0\n",
    "            epoch += 1\n",
    "\n",
    "        # load train data\n",
    "        images, targets = next(batch_iterator)\n",
    "\n",
    "        if cuda:\n",
    "            images = Variable(images.cuda())\n",
    "            targets = [Variable(anno.cuda(), volatile=True) for anno in targets]\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            targets = [Variable(anno, volatile=True) for anno in targets]\n",
    "        # forward\n",
    "        t0 = time.time()\n",
    "        out = net(images)\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss_l, loss_c = criterion(out, targets)\n",
    "        loss = loss_l + loss_c\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        loc_loss += loss_l.data[0]\n",
    "        conf_loss += loss_c.data[0]\n",
    "        if iteration % 10 == 0:\n",
    "            print('Timer: %.4f sec.' % (t1 - t0))\n",
    "            print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.data[0]), end=' ')\n",
    "            if visdom and send_images_to_visdom:\n",
    "                random_batch_index = np.random.randint(images.size(0))\n",
    "                viz.image(images.data[random_batch_index].cpu().numpy())\n",
    "        if visdom:\n",
    "            viz.line(\n",
    "                X=torch.ones((1, 3)).cpu() * iteration,\n",
    "                Y=torch.Tensor([loss_l.data[0], loss_c.data[0],\n",
    "                    loss_l.data[0] + loss_c.data[0]]).unsqueeze(0).cpu(),\n",
    "                win=lot,\n",
    "                update='append'\n",
    "            )\n",
    "            # hacky fencepost solution for 0th epoch plot\n",
    "            if iteration == 0:\n",
    "                viz.line(\n",
    "                    X=torch.zeros((1, 3)).cpu(),\n",
    "                    Y=torch.Tensor([loc_loss, conf_loss,\n",
    "                        loc_loss + conf_loss]).unsqueeze(0).cpu(),\n",
    "                    win=epoch_lot,\n",
    "                    update=True\n",
    "                )\n",
    "        if iteration % 2000 == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(ssd_net.state_dict(), 'weights/ssd300_0712_' +\n",
    "                       repr(iteration) + '.pth')\n",
    "    torch.save(ssd_net.state_dict(), save_folder + '' + version + '.pth')\n",
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-27T06:21:00.856306Z",
     "start_time": "2018-01-27T06:17:31.733317Z"
    }
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
